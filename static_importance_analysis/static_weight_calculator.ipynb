{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c89ab96",
   "metadata": {},
   "source": [
    "# Static Importance Index Calculator for Java Methods\n",
    "\n",
    "This notebook computes static importance indices for Java methods using both **Knowledge Graph** data from Neo4j and **AST** metadata. The goal is to create normalized weights that will be used for method retrieval in a hybrid RAG system for code generation.\n",
    "\n",
    "## Metrics Computed:\n",
    "- **Code Complexity**: LOC, Cyclomatic Complexity, Cognitive Complexity, Halstead Effort\n",
    "- **Graph Centrality**: Degree Centrality, Betweenness Centrality, Eigenvector Centrality\n",
    "- **Method Dependencies**: Fan-in, Fan-out \n",
    "- **Parameter Analysis**: Number of parameters, parameter type complexity, return type complexity\n",
    "\n",
    "## Data Sources:\n",
    "- **Neo4j Knowledge Graph**: `http://4.187.169.27:7474/browser/`\n",
    "- **AST Data**: `../AST/java_parsed.csv`\n",
    "- **Target Project**: Library Management System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9c41c",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries\n",
    "\n",
    "Import all necessary libraries for Neo4j connectivity, data analysis, graph operations, and complexity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8304f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Tree-sitter available: True\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Neo4j connection\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "\n",
    "# Graph analysis\n",
    "import networkx as nx\n",
    "\n",
    "# For complexity calculations\n",
    "import ast\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Set\n",
    "import json\n",
    "\n",
    "# For Java AST parsing\n",
    "try:\n",
    "    from tree_sitter import Language, Parser\n",
    "    from tree_sitter_languages import get_language\n",
    "    TREE_SITTER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"tree-sitter not available. Some complexity metrics will use simplified calculations.\")\n",
    "    TREE_SITTER_AVAILABLE = False\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Tree-sitter available: {TREE_SITTER_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9be61d",
   "metadata": {},
   "source": [
    "## 2. Connect to Neo4j Knowledge Graph\n",
    "\n",
    "Establish connection to the Neo4j database containing the Java knowledge graph and verify connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee96dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Neo4j connection successful!\n",
      "Result: Connection successful\n",
      "\n",
      "üìä Database Statistics:\n",
      "Total nodes: 1,327\n",
      "Total relationships: 6,412\n",
      "Available node labels: ['Import', 'Package', 'Class', 'Constructor', 'Parameter', 'Method', 'Type', 'Annotation', 'Variable', 'Interface', 'Field']\n",
      "Available relationship types: ['INHERITS', 'HAS_CONSTRUCTOR', 'HAS_PARAMETER', 'HAS_METHOD', 'RETURNS', 'HAS_ANNOTATION', 'USES', 'CALLS', 'IMPLEMENTS', 'HAS_FIELD', 'CALLED_BY', 'BELONGS_TO']\n",
      "\n",
      "üîç Call Relationship Analysis:\n",
      "CALLS relationships: 1,900\n",
      "CALLED_BY relationships: 1,900\n"
     ]
    }
   ],
   "source": [
    "# Neo4j connection configuration\n",
    "NEO4J_URI = \"bolt://172.203.167.64:7687\"  # Updated to new Neo4j instance\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"C{&K1r.eZ9*4\"  # Updated password\n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri, username, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters)\n",
    "            return [record for record in result]\n",
    "\n",
    "# Initialize connection\n",
    "neo4j_conn = Neo4jConnection(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "\n",
    "# Test connection and get database info\n",
    "try:\n",
    "    # Test basic connectivity\n",
    "    test_result = neo4j_conn.query(\"RETURN 'Connection successful' as message\")\n",
    "    print(\"‚úÖ Neo4j connection successful!\")\n",
    "    print(f\"Result: {test_result[0]['message']}\")\n",
    "    \n",
    "    # Get database statistics\n",
    "    node_count = neo4j_conn.query(\"MATCH (n) RETURN count(n) as count\")[0]['count']\n",
    "    rel_count = neo4j_conn.query(\"MATCH ()-[r]->() RETURN count(r) as count\")[0]['count']\n",
    "    \n",
    "    print(f\"\\nüìä Database Statistics:\")\n",
    "    print(f\"Total nodes: {node_count:,}\")\n",
    "    print(f\"Total relationships: {rel_count:,}\")\n",
    "    \n",
    "    # Get available node labels\n",
    "    labels_result = neo4j_conn.query(\"CALL db.labels()\")\n",
    "    labels = [record['label'] for record in labels_result]\n",
    "    print(f\"Available node labels: {labels}\")\n",
    "    \n",
    "    # Get available relationship types\n",
    "    rel_types_result = neo4j_conn.query(\"CALL db.relationshipTypes()\")\n",
    "    rel_types = [record['relationshipType'] for record in rel_types_result]\n",
    "    print(f\"Available relationship types: {rel_types}\")\n",
    "    \n",
    "    # Specifically check for CALLS and CALLED_BY relationships\n",
    "    calls_count = neo4j_conn.query(\"MATCH ()-[r:CALLS]->() RETURN count(r) as count\")[0]['count']\n",
    "    called_by_count = neo4j_conn.query(\"MATCH ()-[r:CALLED_BY]->() RETURN count(r) as count\")[0]['count']\n",
    "    print(f\"\\nüîç Call Relationship Analysis:\")\n",
    "    print(f\"CALLS relationships: {calls_count:,}\")\n",
    "    print(f\"CALLED_BY relationships: {called_by_count:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"Please check the Neo4j server status and credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b25c1",
   "metadata": {},
   "source": [
    "## 3. Load AST Data from CSV\n",
    "\n",
    "Load the existing AST parsed data and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8d3546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded AST data: 786 methods found\n",
      "\n",
      "üìä AST Data Overview:\n",
      "Shape: (786, 10)\n",
      "Columns: ['FilePath', 'Package', 'Class', 'Method Name', 'Return Type', 'Parameters', 'Function Body', 'Throws', 'Modifiers', 'Generics']\n",
      "\n",
      "üîç Sample Data:\n",
      "                                            FilePath  Package  \\\n",
      "0  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "1  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "2  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "3  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "4  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "\n",
      "                    Class                Method Name             Return Type  \\\n",
      "0  MavenWrapperDownloader                       main                    void   \n",
      "1  MavenWrapperDownloader        downloadFileFromURL                    void   \n",
      "2  MavenWrapperDownloader  getPasswordAuthentication  PasswordAuthentication   \n",
      "3    PetClinicApplication                       main                    void   \n",
      "4           SwaggerConfig              customOpenAPI                 OpenAPI   \n",
      "\n",
      "                           Parameters  \\\n",
      "0                         String args   \n",
      "1  String urlString, File destination   \n",
      "2                                 NaN   \n",
      "3                       String[] args   \n",
      "4                                 NaN   \n",
      "\n",
      "                                       Function Body            Throws  \\\n",
      "0  {\\n        System.out.println(\"- Downloader st...               NaN   \n",
      "1  {\\n        if (System.getenv(\"MVNW_USERNAME\") ...  throws Exception   \n",
      "2  {\\n                    return new PasswordAuth...               NaN   \n",
      "3  {\\n\\t\\tSpringApplication.run(PetClinicApplicat...               NaN   \n",
      "4  {\\n        return new OpenAPI()\\n            ....               NaN   \n",
      "\n",
      "             Modifiers Generics  \n",
      "0        public static      NaN  \n",
      "1       private static      NaN  \n",
      "2  @Override protected      NaN  \n",
      "3        public static      NaN  \n",
      "4                @Bean      NaN  \n",
      "\n",
      "‚ùì Missing Values:\n",
      "Package          786\n",
      "Parameters       307\n",
      "Function Body    103\n",
      "Throws           567\n",
      "Modifiers         91\n",
      "Generics         784\n",
      "dtype: int64\n",
      "\n",
      "üìà Basic Statistics:\n",
      "Unique classes: 118\n",
      "Unique packages: 0\n",
      "Methods with function body: 683\n",
      "\n",
      "üèóÔ∏è Top 10 Classes by Method Count:\n",
      "Class\n",
      "AbstractClinicServiceTests    35\n",
      "ClinicServiceImpl             30\n",
      "ClinicService                 29\n",
      "OwnerDto                      26\n",
      "OwnerRestControllerTests      25\n",
      "PetDto                        23\n",
      "ProblemDetailDto              23\n",
      "OwnerFieldsDto                19\n",
      "UserDto                       17\n",
      "VetDto                        17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load AST data from CSV\n",
    "ast_file_path = \"../methods.csv\"\n",
    "\n",
    "try:\n",
    "    ast_df = pd.read_csv(ast_file_path)\n",
    "    print(f\"‚úÖ Successfully loaded AST data: {len(ast_df)} methods found\")\n",
    "    \n",
    "    # Basic data exploration\n",
    "    print(f\"\\nüìä AST Data Overview:\")\n",
    "    print(f\"Shape: {ast_df.shape}\")\n",
    "    print(f\"Columns: {list(ast_df.columns)}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(f\"\\nüîç Sample Data:\")\n",
    "    print(ast_df.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\n‚ùì Missing Values:\")\n",
    "    missing_counts = ast_df.isnull().sum()\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìà Basic Statistics:\")\n",
    "    print(f\"Unique classes: {ast_df['Class'].nunique()}\")\n",
    "    print(f\"Unique packages: {ast_df['Package'].nunique()}\")\n",
    "    print(f\"Methods with function body: {ast_df['Function Body'].notna().sum()}\")\n",
    "    \n",
    "    # Method distribution by class\n",
    "    method_counts = ast_df['Class'].value_counts()\n",
    "    print(f\"\\nüèóÔ∏è Top 10 Classes by Method Count:\")\n",
    "    print(method_counts.head(10))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Could not find AST file at: {ast_file_path}\")\n",
    "    print(\"Please ensure the AST parsing has been completed and the file exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading AST data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5cc522",
   "metadata": {},
   "source": [
    "## 4. Extract Method Information from Knowledge Graph\n",
    "\n",
    "Query the Neo4j graph to extract method nodes and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c2f9b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Extracting method nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 4, column: 12, offset: 68} for query: '\\n    MATCH (m:Method)\\n    RETURN m.name as method_name, \\n           id(m) as node_id,\\n           m.depth as depth,\\n           labels(m) as labels\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 475 method nodes\n",
      "üîÑ Extracting CALLS and CALLED_BY relationships...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 6, column: 12, offset: 172} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 7, column: 12, offset: 204} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 13, column: 12, offset: 417} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 14, column: 12, offset: 449} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3800 call relationships\n",
      "üìä Relationship type distribution:\n",
      "  CALLS: 1900\n",
      "  CALLED_BY: 1900\n",
      "üîÑ Extracting method-class relationships...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 5, column: 12, offset: 126} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 6, column: 12, offset: 156} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 11, column: 12, offset: 314} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 12, column: 12, offset: 344} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 922 method-class relationships\n",
      "üîÑ Extracting method parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 5, column: 12, offset: 123} for query: '\\n    MATCH (m:Method)-[r:HAS_PARAMETER]->(p)\\n    RETURN m.name as method_name,\\n           p.name as param_name,\\n           id(m) as method_id,\\n           id(p) as param_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 6, column: 12, offset: 154} for query: '\\n    MATCH (m:Method)-[r:HAS_PARAMETER]->(p)\\n    RETURN m.name as method_name,\\n           p.name as param_name,\\n           id(m) as method_id,\\n           id(p) as param_id\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 method parameters\n",
      "\n",
      "üîç Call Graph Analysis:\n",
      "Unique calling methods: 457\n",
      "Unique called methods: 457\n",
      "\n",
      "üìã Sample call relationships:\n",
      "  toString -CALLS-> getId\n",
      "  toString -CALLS-> isNew\n",
      "  toString -CALLS-> getLastName\n",
      "  toString -CALLS-> getFirstName\n",
      "  toString -CALLS-> append\n",
      "  toString -CALLS-> toString\n",
      "  toString -CALLS-> getName\n",
      "  getPets -CALLS-> unmodifiableList\n",
      "  getPets -CALLS-> sort\n",
      "  getPets -CALLS-> getPetsInternal\n",
      "\n",
      "‚úÖ Knowledge Graph data extracted successfully!\n",
      "\n",
      "üìä METHODS Sample:\n",
      "   method_name  node_id  depth    labels\n",
      "0  toVisitsDto        1      1  [Method]\n",
      "1        getId       15      1  [Method]\n",
      "2        setId       17      1  [Method]\n",
      "3        isNew       20      1  [Method]\n",
      "4      getName       28      1  [Method]\n",
      "Shape: (475, 4)\n",
      "\n",
      "üìä RELATIONSHIPS Sample:\n",
      "  source_method target_method relationship_type  source_id  target_id\n",
      "0      toString         getId             CALLS         31         15\n",
      "1      toString         isNew             CALLS         31         20\n",
      "2      toString   getLastName             CALLS         31         87\n",
      "3      toString  getFirstName             CALLS         31         86\n",
      "4      toString        append             CALLS         31         85\n",
      "Shape: (3800, 5)\n",
      "\n",
      "üìä METHOD_CLASS Sample:\n",
      "    class_name method_name  class_id  method_id\n",
      "0   BaseEntity       isNew        11         20\n",
      "1   BaseEntity       setId        11         17\n",
      "2   BaseEntity       getId        11         15\n",
      "3  NamedEntity    toString        25         31\n",
      "4  NamedEntity     setName        25       1111\n",
      "Shape: (922, 4)\n",
      "\n",
      "üìä METHOD_PARAMS Sample:\n",
      "No data found\n"
     ]
    }
   ],
   "source": [
    "# Extract method information from Knowledge Graph\n",
    "def extract_kg_data():\n",
    "    \"\"\"Extract all relevant data from the knowledge graph, focusing on CALLS and CALLED_BY relationships\"\"\"\n",
    "    \n",
    "    # Get all method nodes\n",
    "    methods_query = \"\"\"\n",
    "    MATCH (m:Method)\n",
    "    RETURN m.name as method_name, \n",
    "           id(m) as node_id,\n",
    "           m.depth as depth,\n",
    "           labels(m) as labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get CALLS and CALLED_BY relationships specifically\n",
    "    calls_relationships_query = \"\"\"\n",
    "    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\n",
    "    RETURN m1.name as source_method,\n",
    "           m2.name as target_method,\n",
    "           'CALLS' as relationship_type,\n",
    "           id(m1) as source_id,\n",
    "           id(m2) as target_id\n",
    "    UNION ALL\n",
    "    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\n",
    "    RETURN m1.name as source_method,\n",
    "           m2.name as target_method,\n",
    "           'CALLED_BY' as relationship_type,\n",
    "           id(m1) as source_id,\n",
    "           id(m2) as target_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get method-class relationships\n",
    "    method_class_query = \"\"\"\n",
    "    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\n",
    "    RETURN c.name as class_name,\n",
    "           m.name as method_name,\n",
    "           id(c) as class_id,\n",
    "           id(m) as method_id\n",
    "    UNION ALL\n",
    "    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\n",
    "    RETURN c.name as class_name,\n",
    "           m.name as method_name,\n",
    "           id(c) as class_id,\n",
    "           id(m) as method_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get method parameters\n",
    "    method_params_query = \"\"\"\n",
    "    MATCH (m:Method)-[r:HAS_PARAMETER]->(p)\n",
    "    RETURN m.name as method_name,\n",
    "           p.name as param_name,\n",
    "           id(m) as method_id,\n",
    "           id(p) as param_id\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Extracting method nodes...\")\n",
    "        methods_data = neo4j_conn.query(methods_query)\n",
    "        methods_df = pd.DataFrame([dict(record) for record in methods_data])\n",
    "        print(f\"Found {len(methods_df)} method nodes\")\n",
    "        \n",
    "        print(\"üîÑ Extracting CALLS and CALLED_BY relationships...\")\n",
    "        relationships_data = neo4j_conn.query(calls_relationships_query)\n",
    "        relationships_df = pd.DataFrame([dict(record) for record in relationships_data])\n",
    "        print(f\"Found {len(relationships_df)} call relationships\")\n",
    "        \n",
    "        # Analyze the distribution of relationship types\n",
    "        if not relationships_df.empty:\n",
    "            rel_distribution = relationships_df['relationship_type'].value_counts()\n",
    "            print(f\"üìä Relationship type distribution:\")\n",
    "            for rel_type, count in rel_distribution.items():\n",
    "                print(f\"  {rel_type}: {count}\")\n",
    "        \n",
    "        print(\"üîÑ Extracting method-class relationships...\")\n",
    "        method_class_data = neo4j_conn.query(method_class_query)\n",
    "        method_class_df = pd.DataFrame([dict(record) for record in method_class_data])\n",
    "        print(f\"Found {len(method_class_df)} method-class relationships\")\n",
    "        \n",
    "        print(\"üîÑ Extracting method parameters...\")\n",
    "        method_params_data = neo4j_conn.query(method_params_query)\n",
    "        method_params_df = pd.DataFrame([dict(record) for record in method_params_data])\n",
    "        print(f\"Found {len(method_params_df)} method parameters\")\n",
    "        \n",
    "        # Additional analysis of the call graph structure\n",
    "        if not relationships_df.empty:\n",
    "            unique_callers = relationships_df['source_method'].nunique()\n",
    "            unique_callees = relationships_df['target_method'].nunique()\n",
    "            print(f\"\\nüîç Call Graph Analysis:\")\n",
    "            print(f\"Unique calling methods: {unique_callers}\")\n",
    "            print(f\"Unique called methods: {unique_callees}\")\n",
    "            \n",
    "            # Show sample relationships\n",
    "            print(f\"\\nüìã Sample call relationships:\")\n",
    "            sample_rels = relationships_df.head(10)\n",
    "            for _, row in sample_rels.iterrows():\n",
    "                print(f\"  {row['source_method']} -{row['relationship_type']}-> {row['target_method']}\")\n",
    "        \n",
    "        return {\n",
    "            'methods': methods_df,\n",
    "            'relationships': relationships_df,\n",
    "            'method_class': method_class_df,\n",
    "            'method_params': method_params_df\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting KG data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract the data\n",
    "kg_data = extract_kg_data()\n",
    "\n",
    "if kg_data:\n",
    "    print(\"\\n‚úÖ Knowledge Graph data extracted successfully!\")\n",
    "    \n",
    "    # Display sample data\n",
    "    for key, df in kg_data.items():\n",
    "        print(f\"\\nüìä {key.upper()} Sample:\")\n",
    "        if not df.empty:\n",
    "            print(df.head())\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(\"No data found\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to extract knowledge graph data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a597e58",
   "metadata": {},
   "source": [
    "## 5. Generate Method Dictionary with Line of Code Counts\n",
    "\n",
    "This section creates a dictionary (list of dictionaries) containing each method name and its corresponding line of code count. The line of code count is calculated by:\n",
    "\n",
    "1. Parsing the function body from the CSV data\n",
    "2. Splitting into individual lines\n",
    "3. Filtering out empty lines and comments\n",
    "4. Counting the remaining code lines\n",
    "\n",
    "The output format will be:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"method_name\": \"methodA\",\n",
    "        \"line_of_code\": 40\n",
    "    },\n",
    "    {\n",
    "        \"method_name\": \"methodB\", \n",
    "        \"line_of_code\": 20\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "746a8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ extract_lines_of_code function defined successfully!\n",
      "üìù Test function LOC: 1\n",
      "Function is ready to use!\n"
     ]
    }
   ],
   "source": [
    "def extract_lines_of_code(function_body):\n",
    "    \"\"\"\n",
    "    Extract the number of lines of code from a function body string.\n",
    "    Handles various edge cases and formats.\n",
    "    \n",
    "    Args:\n",
    "        function_body (str): The function body code as a string\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of lines of code (excluding empty lines and comments)\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return 0\n",
    "    \n",
    "    # Convert to string if not already\n",
    "    function_body = str(function_body)\n",
    "    \n",
    "    # Split by lines and filter out empty lines and comments\n",
    "    lines = function_body.split('\\\\n')\n",
    "    \n",
    "    # Count non-empty lines (excluding pure whitespace and single-line comments)\n",
    "    code_lines = []\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # Skip empty lines\n",
    "        if not stripped_line:\n",
    "            continue\n",
    "        # Skip single-line comments (// or /* ... */)\n",
    "        if stripped_line.startswith('//') or (stripped_line.startswith('/*') and stripped_line.endswith('*/')):\n",
    "            continue\n",
    "        code_lines.append(line)\n",
    "    \n",
    "    return len(code_lines)\n",
    "\n",
    "# Test the function with a sample\n",
    "print(\"‚úÖ extract_lines_of_code function defined successfully!\")\n",
    "\n",
    "# Test with a sample function body\n",
    "test_function_body = \"\"\"\n",
    "public void testMethod() {\n",
    "    // This is a comment\n",
    "    int x = 5;\n",
    "    if (x > 0) {\n",
    "        System.out.println(\"Positive\");\n",
    "    }\n",
    "    /* Another comment */\n",
    "    return;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "test_loc = extract_lines_of_code(test_function_body)\n",
    "print(f\"üìù Test function LOC: {test_loc}\")\n",
    "print(\"Function is ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "befa99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating enhanced method dictionary with unique identifiers...\n",
      "Available columns in ast_df: ['FilePath', 'Package', 'Class', 'Method Name', 'Return Type', 'Parameters', 'Function Body', 'Throws', 'Modifiers', 'Generics']\n",
      "\n",
      "Sample row to understand data structure:\n",
      "  FilePath: C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\spring-petclinic-rest\\.mvn\\wrapper\\MavenWrapperDownloader.java\n",
      "  Package: nan\n",
      "  Class: MavenWrapperDownloader\n",
      "  Method Name: main\n",
      "  Return Type: void\n",
      "  Parameters: String args\n",
      "  Function Body: {\\n        System.out.println(\"- Downloader started\");\\n        File baseDirectory = new File(args[0]);\\n        System.out.println(\"- Using base directory: \" + baseDirectory.getAbsolutePath());\\n\\n        // If the maven-wrapper.properties exists, read it and check if it contains a custom\\n        // wrapperUrl parameter.\\n        File mavenWrapperPropertyFile = new File(baseDirectory, MAVEN_WRAPPER_PROPERTIES_PATH);\\n        String url = DEFAULT_DOWNLOAD_URL;\\n        if(mavenWrapperPropertyFile.exists()) {\\n            FileInputStream mavenWrapperPropertyFileInputStream = null;\\n            try {\\n                mavenWrapperPropertyFileInputStream = new FileInputStream(mavenWrapperPropertyFile);\\n                Properties mavenWrapperProperties = new Properties();\\n                mavenWrapperProperties.load(mavenWrapperPropertyFileInputStream);\\n                url = mavenWrapperProperties.getProperty(PROPERTY_NAME_WRAPPER_URL, url);\\n            } catch (IOException e) {\\n                System.out.println(\"- ERROR loading '\" + MAVEN_WRAPPER_PROPERTIES_PATH + \"'\");\\n            } finally {\\n                try {\\n                    if(mavenWrapperPropertyFileInputStream != null) {\\n                        mavenWrapperPropertyFileInputStream.close();\\n                    }\\n                } catch (IOException e) {\\n                    // Ignore ...\\n                }\\n            }\\n        }\\n        System.out.println(\"- Downloading from: \" + url);\\n\\n        File outputFile = new File(baseDirectory.getAbsolutePath(), MAVEN_WRAPPER_JAR_PATH);\\n        if(!outputFile.getParentFile().exists()) {\\n            if(!outputFile.getParentFile().mkdirs()) {\\n                System.out.println(\\n                        \"- ERROR creating output directory '\" + outputFile.getParentFile().getAbsolutePath() + \"'\");\\n            }\\n        }\\n        System.out.println(\"- Downloading to: \" + outputFile.getAbsolutePath());\\n        try {\\n            downloadFileFromURL(url, outputFile);\\n            System.out.println(\"Done\");\\n            System.exit(0);\\n        } catch (Throwable e) {\\n            System.out.println(\"- Error downloading\");\\n            e.printStackTrace();\\n            System.exit(1);\\n        }\\n    }\n",
      "  Throws: nan\n",
      "  Modifiers: public static\n",
      "  Generics: nan\n",
      "‚úÖ Generated enhanced dictionary for 786 methods\n",
      "\n",
      "üìã Sample enhanced entries (first 10):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   Parameters: String args\n",
      "   Return Type: void\n",
      "   LOC: 43\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   Parameters: String urlString, File destination\n",
      "   Return Type: void\n",
      "   LOC: 19\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   Parameters: \n",
      "   Return Type: PasswordAuthentication\n",
      "   LOC: 3\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   Parameters: String[] args\n",
      "   Return Type: void\n",
      "   LOC: 3\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   Parameters: \n",
      "   Return Type: OpenAPI\n",
      "   LOC: 13\n",
      "   ---\n",
      "6. Method: 'swaggerContact'\n",
      "   Class: SwaggerConfig\n",
      "   Parameters: \n",
      "   Return Type: Contact\n",
      "   LOC: 7\n",
      "   ---\n",
      "7. Method: 'swaggerLicense'\n",
      "   Class: SwaggerConfig\n",
      "   Parameters: \n",
      "   Return Type: License\n",
      "   LOC: 7\n",
      "   ---\n",
      "8. Method: 'toOwnerDto'\n",
      "   Class: OwnerMapper\n",
      "   Parameters: Owner owner\n",
      "   Return Type: OwnerDto\n",
      "   LOC: 0\n",
      "   ---\n",
      "9. Method: 'toOwner'\n",
      "   Class: OwnerMapper\n",
      "   Parameters: OwnerDto ownerDto\n",
      "   Return Type: Owner\n",
      "   LOC: 0\n",
      "   ---\n",
      "10. Method: 'toOwner'\n",
      "   Class: OwnerMapper\n",
      "   Parameters: OwnerFieldsDto ownerDto\n",
      "   Return Type: Owner\n",
      "   LOC: 0\n",
      "   ---\n",
      "\n",
      "üìä Method Name Analysis:\n",
      "Total unique method names: 377\n",
      "Method names with duplicates: 155\n",
      "Top 10 most common method names:\n",
      "  'delete': 26 occurrences\n",
      "  'save': 21 occurrences\n",
      "  'toString': 19 occurrences\n",
      "  'findById': 19 occurrences\n",
      "  'findAll': 18 occurrences\n",
      "  'equals': 15 occurrences\n",
      "  'hashCode': 15 occurrences\n",
      "  'toIndentedString': 15 occurrences\n",
      "  'getName': 8 occurrences\n",
      "  'setName': 8 occurrences\n",
      "\n",
      "üîç Unique Method Signature Analysis:\n",
      "Total methods: 786\n",
      "Unique method signatures: 785\n",
      "Duplicate signatures found: 1\n",
      "Sample duplicate signatures:\n",
      "  1. mapRow in JdbcVetRepositoryImpl with params: ResultSet rs, int row\n",
      "\n",
      "üíæ Enhanced dictionary saved to: enhanced_methods_dictionary.json\n",
      "‚úÖ Enhanced dictionary is available in the 'enhanced_methods_dict_list' variable\n",
      "\n",
      "Format: List of dictionaries with keys:\n",
      "  - 'method_name': Method name\n",
      "  - 'parameters': Method parameters\n",
      "  - 'return_type': Return type\n",
      "  - 'class': Class containing the method\n",
      "  - 'line_of_code': Lines of code count\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Method Dictionary Generation with Unique Identifiers\n",
    "print(\"üîÑ Generating enhanced method dictionary with unique identifiers...\")\n",
    "\n",
    "# First, let's examine the available columns to understand the data structure\n",
    "print(f\"Available columns in ast_df: {list(ast_df.columns)}\")\n",
    "print(f\"\\nSample row to understand data structure:\")\n",
    "if len(ast_df) > 0:\n",
    "    sample_row = ast_df.iloc[0]\n",
    "    for col in ast_df.columns:\n",
    "        print(f\"  {col}: {sample_row[col]}\")\n",
    "\n",
    "# Enhanced dictionary generation with unique method identification\n",
    "enhanced_methods_dict_list = []\n",
    "\n",
    "for index, row in ast_df.iterrows():\n",
    "    # Extract all required fields for unique identification\n",
    "    method_name = row.get('Method Name', row.get('Method', ''))\n",
    "    parameters = row.get('Parameters', row.get('Parameter', ''))\n",
    "    return_type = row.get('Return Type', row.get('ReturnType', ''))\n",
    "    class_name = row.get('Class', row.get('ClassName', ''))\n",
    "    function_body = row.get('Function Body', '')\n",
    "    \n",
    "    # Calculate lines of code\n",
    "    loc = extract_lines_of_code(function_body)\n",
    "    \n",
    "    # Clean up the data - handle NaN/null values\n",
    "    method_name = str(method_name) if pd.notna(method_name) else \"\"\n",
    "    parameters = str(parameters) if pd.notna(parameters) else \"\"\n",
    "    return_type = str(return_type) if pd.notna(return_type) else \"\"\n",
    "    class_name = str(class_name) if pd.notna(class_name) else \"\"\n",
    "    \n",
    "    # Create enhanced dictionary entry with unique identifiers\n",
    "    method_entry = {\n",
    "        \"method_name\": method_name,\n",
    "        \"parameters\": parameters,\n",
    "        \"return_type\": return_type,\n",
    "        \"class\": class_name,\n",
    "        \"function_body\": function_body,\n",
    "        \"line_of_code\": loc\n",
    "    }\n",
    "    enhanced_methods_dict_list.append(method_entry)\n",
    "\n",
    "print(f\"‚úÖ Generated enhanced dictionary for {len(enhanced_methods_dict_list)} methods\")\n",
    "\n",
    "# Display first 10 entries as sample\n",
    "print(f\"\\nüìã Sample enhanced entries (first 10):\")\n",
    "for i, method in enumerate(enhanced_methods_dict_list[:10]):\n",
    "    print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "    print(f\"   Class: {method['class']}\")\n",
    "    print(f\"   Parameters: {method['parameters']}\")\n",
    "    print(f\"   Return Type: {method['return_type']}\")\n",
    "    print(f\"   LOC: {method['line_of_code']}\")\n",
    "    print(\"   ---\")\n",
    "\n",
    "# Analyze method name duplicates\n",
    "method_names = [method['method_name'] for method in enhanced_methods_dict_list]\n",
    "method_name_counts = Counter(method_names)\n",
    "duplicates = {name: count for name, count in method_name_counts.items() if count > 1}\n",
    "\n",
    "print(f\"\\nüìä Method Name Analysis:\")\n",
    "print(f\"Total unique method names: {len(method_name_counts)}\")\n",
    "print(f\"Method names with duplicates: {len(duplicates)}\")\n",
    "if duplicates:\n",
    "    print(f\"Top 10 most common method names:\")\n",
    "    for name, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"  '{name}': {count} occurrences\")\n",
    "\n",
    "# Check for truly unique methods (considering all 4 identifiers)\n",
    "unique_signatures = set()\n",
    "duplicate_signatures = []\n",
    "\n",
    "for method in enhanced_methods_dict_list:\n",
    "    signature = (method['method_name'], method['parameters'], method['return_type'], method['class'])\n",
    "    if signature in unique_signatures:\n",
    "        duplicate_signatures.append(signature)\n",
    "    else:\n",
    "        unique_signatures.add(signature)\n",
    "\n",
    "print(f\"\\nüîç Unique Method Signature Analysis:\")\n",
    "print(f\"Total methods: {len(enhanced_methods_dict_list)}\")\n",
    "print(f\"Unique method signatures: {len(unique_signatures)}\")\n",
    "print(f\"Duplicate signatures found: {len(duplicate_signatures)}\")\n",
    "\n",
    "if duplicate_signatures:\n",
    "    print(f\"Sample duplicate signatures:\")\n",
    "    for i, sig in enumerate(duplicate_signatures[:5]):\n",
    "        print(f\"  {i+1}. {sig[0]} in {sig[3]} with params: {sig[1]}\")\n",
    "\n",
    "# Save enhanced dictionary to JSON file\n",
    "enhanced_output_filename = \"enhanced_methods_dictionary.json\"\n",
    "with open(enhanced_output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Enhanced dictionary saved to: {enhanced_output_filename}\")\n",
    "print(f\"‚úÖ Enhanced dictionary is available in the 'enhanced_methods_dict_list' variable\")\n",
    "print(f\"\\nFormat: List of dictionaries with keys:\")\n",
    "print(f\"  - 'method_name': Method name\")\n",
    "print(f\"  - 'parameters': Method parameters\") \n",
    "print(f\"  - 'return_type': Return type\")\n",
    "print(f\"  - 'class': Class containing the method\")\n",
    "print(f\"  - 'line_of_code': Lines of code count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4848fbf9",
   "metadata": {},
   "source": [
    "## 6. Add Cyclomatic Complexity to Method Dictionary\n",
    "\n",
    "Calculate Cyclomatic Complexity for each method and add it to the enhanced method dictionary. Cyclomatic Complexity measures the number of linearly independent paths through a program's source code.\n",
    "\n",
    "**Formula**: CC = E - N + 2P\n",
    "- E = number of edges in the control flow graph\n",
    "- N = number of nodes in the control flow graph  \n",
    "- P = number of connected components\n",
    "\n",
    "**Simplified Calculation**: Count decision points (if, while, for, switch, etc.) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb385c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Calculating Cyclomatic Complexity for all methods...\n",
      "‚úÖ Updated 786 methods with Cyclomatic Complexity\n",
      "\n",
      "üìä Cyclomatic Complexity Statistics:\n",
      "Average CC: 1.59\n",
      "Median CC: 1.00\n",
      "Min CC: 1\n",
      "Max CC: 10\n",
      "Standard Deviation: 1.32\n",
      "\n",
      "üìà Complexity Distribution (top 10):\n",
      "  CC 1: 570 methods (72.5%)\n",
      "  CC 2: 127 methods (16.2%)\n",
      "  CC 3: 33 methods (4.2%)\n",
      "  CC 6: 29 methods (3.7%)\n",
      "  CC 4: 13 methods (1.7%)\n",
      "  CC 5: 6 methods (0.8%)\n",
      "  CC 7: 3 methods (0.4%)\n",
      "  CC 10: 2 methods (0.3%)\n",
      "  CC 9: 2 methods (0.3%)\n",
      "  CC 8: 1 methods (0.1%)\n",
      "\n",
      "üìã Sample updated entries with Cyclomatic Complexity (first 5):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 43\n",
      "   Cyclomatic Complexity: 10\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 19\n",
      "   Cyclomatic Complexity: 3\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   LOC: 13\n",
      "   Cyclomatic Complexity: 2\n",
      "   ---\n",
      "\n",
      "üîù Top 10 methods by Cyclomatic Complexity:\n",
      "1. main (Class: MavenWrapperDownloader)\n",
      "   CC: 10, LOC: 43\n",
      "2. equals (Class: OwnerDto)\n",
      "   CC: 10, LOC: 16\n",
      "3. equals (Class: PetDto)\n",
      "   CC: 9, LOC: 15\n",
      "4. equals (Class: ProblemDetailDto)\n",
      "   CC: 9, LOC: 15\n",
      "5. equals (Class: OwnerFieldsDto)\n",
      "   CC: 8, LOC: 14\n",
      "6. equals (Class: UserDto)\n",
      "   CC: 7, LOC: 13\n",
      "7. equals (Class: VetDto)\n",
      "   CC: 7, LOC: 13\n",
      "8. equals (Class: VisitDto)\n",
      "   CC: 7, LOC: 13\n",
      "9. saveUser (Class: UserServiceImpl)\n",
      "   CC: 6, LOC: 14\n",
      "10. addPetToOwner (Class: OwnersApi)\n",
      "   CC: 6, LOC: 27\n",
      "\n",
      "üíæ Updated dictionary with Cyclomatic Complexity saved to: enhanced_methods_with_complexity.json\n",
      "‚úÖ Enhanced dictionary now includes:\n",
      "  - method_name, parameters, return_type, class\n",
      "  - line_of_code\n",
      "  - cyclomatic_complexity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cyclomatic_complexity(function_body):\n",
    "    \"\"\"\n",
    "    Calculate Cyclomatic Complexity for a given function body.\n",
    "    \n",
    "    Simplified calculation: Count decision points + 1\n",
    "    Decision points include: if, else if, while, for, do-while, switch, case, \n",
    "    catch, ternary operators (?:), logical operators (&&, ||)\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return 1  # Base complexity for empty method\n",
    "    \n",
    "    function_body = str(function_body)\n",
    "    \n",
    "    # Initialize complexity (base complexity is 1)\n",
    "    complexity = 1\n",
    "    \n",
    "    # Keywords that add to cyclomatic complexity\n",
    "    decision_keywords = [\n",
    "        'if', 'else if', 'elseif', 'while', 'for', 'do', \n",
    "        'switch', 'case', 'catch', 'forEach'\n",
    "    ]\n",
    "    \n",
    "    # Convert to lowercase for case-insensitive matching\n",
    "    function_lower = function_body.lower()\n",
    "    \n",
    "    # Count decision keywords\n",
    "    for keyword in decision_keywords:\n",
    "        # Use word boundaries to avoid matching substrings\n",
    "        import re\n",
    "        pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "        matches = re.findall(pattern, function_lower)\n",
    "        complexity += len(matches)\n",
    "    \n",
    "    # Count logical operators (&&, ||) that create additional paths\n",
    "    logical_and_count = len(re.findall(r'&&', function_body))\n",
    "    logical_or_count = len(re.findall(r'\\|\\|', function_body))\n",
    "    complexity += logical_and_count + logical_or_count\n",
    "    \n",
    "    # Count ternary operators (?:)\n",
    "    ternary_count = len(re.findall(r'\\?[^?]*:', function_body))\n",
    "    complexity += ternary_count\n",
    "    \n",
    "    return max(1, complexity)  # Minimum complexity is 1\n",
    "\n",
    "# Calculate Cyclomatic Complexity for all methods and update the enhanced dictionary\n",
    "print(\"üîÑ Calculating Cyclomatic Complexity for all methods...\")\n",
    "\n",
    "# Check if enhanced_methods_dict_list exists\n",
    "if 'enhanced_methods_dict_list' not in globals():\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cell first.\")\n",
    "else:\n",
    "    # Create a copy to avoid modifying during iteration\n",
    "    updated_methods_list = []\n",
    "    \n",
    "    for i, method_entry in enumerate(enhanced_methods_dict_list):\n",
    "        # Get the original function body from ast_df for this method\n",
    "        method_name = method_entry['method_name']\n",
    "        class_name = method_entry['class']\n",
    "        \n",
    "        # Find the corresponding row in ast_df\n",
    "        matching_rows = ast_df[\n",
    "            (ast_df['Method Name'] == method_name) & \n",
    "            (ast_df['Class'] == class_name)\n",
    "        ]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            function_body = matching_rows.iloc[0]['Function Body']\n",
    "        else:\n",
    "            function_body = ''\n",
    "        \n",
    "        # Calculate cyclomatic complexity\n",
    "        cyclomatic_complexity = calculate_cyclomatic_complexity(function_body)\n",
    "        \n",
    "        # Create updated method entry with cyclomatic complexity\n",
    "        updated_method_entry = method_entry.copy()\n",
    "        updated_method_entry['cyclomatic_complexity'] = cyclomatic_complexity\n",
    "        \n",
    "        updated_methods_list.append(updated_method_entry)\n",
    "    \n",
    "    # Update the enhanced_methods_dict_list\n",
    "    enhanced_methods_dict_list = updated_methods_list\n",
    "    \n",
    "    print(f\"‚úÖ Updated {len(enhanced_methods_dict_list)} methods with Cyclomatic Complexity\")\n",
    "    \n",
    "    # Display statistics\n",
    "    complexity_values = [method['cyclomatic_complexity'] for method in enhanced_methods_dict_list]\n",
    "    \n",
    "    print(f\"\\nüìä Cyclomatic Complexity Statistics:\")\n",
    "    print(f\"Average CC: {np.mean(complexity_values):.2f}\")\n",
    "    print(f\"Median CC: {np.median(complexity_values):.2f}\")\n",
    "    print(f\"Min CC: {min(complexity_values)}\")\n",
    "    print(f\"Max CC: {max(complexity_values)}\")\n",
    "    print(f\"Standard Deviation: {np.std(complexity_values):.2f}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    complexity_counts = Counter(complexity_values)\n",
    "    print(f\"\\nüìà Complexity Distribution (top 10):\")\n",
    "    for cc, count in complexity_counts.most_common(10):\n",
    "        print(f\"  CC {cc}: {count} methods ({count/len(complexity_values)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample updated entries\n",
    "    print(f\"\\nüìã Sample updated entries with Cyclomatic Complexity (first 5):\")\n",
    "    for i, method in enumerate(enhanced_methods_dict_list[:5]):\n",
    "        print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "        print(f\"   Class: {method['class']}\")\n",
    "        print(f\"   LOC: {method['line_of_code']}\")\n",
    "        print(f\"   Cyclomatic Complexity: {method['cyclomatic_complexity']}\")\n",
    "        print(\"   ---\")\n",
    "    \n",
    "    # Show methods with highest cyclomatic complexity\n",
    "    sorted_by_complexity = sorted(enhanced_methods_dict_list, \n",
    "                                key=lambda x: x['cyclomatic_complexity'], \n",
    "                                reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 methods by Cyclomatic Complexity:\")\n",
    "    for i, method in enumerate(sorted_by_complexity[:10]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   CC: {method['cyclomatic_complexity']}, LOC: {method['line_of_code']}\")\n",
    "    \n",
    "    # Update the JSON file with cyclomatic complexity\n",
    "    updated_output_filename = \"enhanced_methods_with_complexity.json\"\n",
    "    with open(updated_output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Updated dictionary with Cyclomatic Complexity saved to: {updated_output_filename}\")\n",
    "    print(f\"‚úÖ Enhanced dictionary now includes:\")\n",
    "    print(f\"  - method_name, parameters, return_type, class\")\n",
    "    print(f\"  - line_of_code\")\n",
    "    print(f\"  - cyclomatic_complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4acf07",
   "metadata": {},
   "source": [
    "## 7. Add Cognitive Complexity to Method Dictionary\n",
    "\n",
    "Calculate Cognitive Complexity for each method and add it to the enhanced method dictionary. Cognitive Complexity is a measure of how difficult the code is to understand, focusing on the mental burden when reading code.\n",
    "\n",
    "**Key Differences from Cyclomatic Complexity:**\n",
    "- **Nesting increases complexity**: Nested control structures add more complexity\n",
    "- **Certain constructs are ignored**: `else`, `case`, `default` don't add complexity\n",
    "- **Binary logical operators**: Each use of `&&`, `||` in conditions adds +1\n",
    "- **Recursion**: Recursive calls add complexity\n",
    "\n",
    "**Cognitive Complexity Rules:**\n",
    "1. Base complexity = 0 (not 1 like Cyclomatic)\n",
    "2. Increment by 1 for: `if`, `while`, `for`, `do-while`, `switch`, `catch`, `goto`, `break`, `continue`\n",
    "3. Increment by nesting level for nested control structures\n",
    "4. Binary logical operators (`&&`, `||`) in conditions add +1 each\n",
    "5. Recursive calls add +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a82a4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Calculating Cognitive Complexity for all methods...\n",
      "‚úÖ Updated 786 methods with Cognitive Complexity\n",
      "\n",
      "üìä Cognitive Complexity Statistics:\n",
      "Average Cognitive Complexity: 0.69\n",
      "Median Cognitive Complexity: 0.00\n",
      "Min Cognitive Complexity: 0\n",
      "Max Cognitive Complexity: 9\n",
      "Standard Deviation: 1.53\n",
      "\n",
      "üîÑ Comparison with Cyclomatic Complexity:\n",
      "Average CC: 1.59 vs Cognitive: 0.69\n",
      "Correlation between CC and Cognitive: 0.944\n",
      "\n",
      "üìà Cognitive Complexity Distribution (top 10):\n",
      "  Cognitive 0: 555 methods (70.6%)\n",
      "  Cognitive 1: 144 methods (18.3%)\n",
      "  Cognitive 6: 38 methods (4.8%)\n",
      "  Cognitive 3: 28 methods (3.6%)\n",
      "  Cognitive 2: 9 methods (1.1%)\n",
      "  Cognitive 4: 6 methods (0.8%)\n",
      "  Cognitive 8: 2 methods (0.3%)\n",
      "  Cognitive 5: 2 methods (0.3%)\n",
      "  Cognitive 9: 1 methods (0.1%)\n",
      "  Cognitive 7: 1 methods (0.1%)\n",
      "\n",
      "üìã Sample updated entries with both complexities (first 5):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 43\n",
      "   Cyclomatic Complexity: 10\n",
      "   Cognitive Complexity: 3\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 19\n",
      "   Cyclomatic Complexity: 3\n",
      "   Cognitive Complexity: 2\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   Cognitive Complexity: 0\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   Cognitive Complexity: 0\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   LOC: 13\n",
      "   Cyclomatic Complexity: 2\n",
      "   Cognitive Complexity: 1\n",
      "   ---\n",
      "\n",
      "üîù Top 10 methods by Cognitive Complexity:\n",
      "1. equals (Class: OwnerDto)\n",
      "   Cognitive: 9, Cyclomatic: 10, LOC: 16\n",
      "2. equals (Class: PetDto)\n",
      "   Cognitive: 8, Cyclomatic: 9, LOC: 15\n",
      "3. equals (Class: ProblemDetailDto)\n",
      "   Cognitive: 8, Cyclomatic: 9, LOC: 15\n",
      "4. equals (Class: OwnerFieldsDto)\n",
      "   Cognitive: 7, Cyclomatic: 8, LOC: 14\n",
      "5. failingRequest (Class: OopsApi)\n",
      "   Cognitive: 6, Cyclomatic: 3, LOC: 12\n",
      "6. addOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 5, LOC: 22\n",
      "7. addPetToOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "8. addVisitToOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "9. deleteOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "10. getOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "\n",
      "üéØ Top 5 methods with largest Cognitive vs Cyclomatic difference:\n",
      "1. main (Class: MavenWrapperDownloader)\n",
      "   Cognitive: 3, Cyclomatic: 10, Diff: 7\n",
      "2. findAll (Class: JdbcVetRepositoryImpl)\n",
      "   Cognitive: 1, Cyclomatic: 4, Diff: 3\n",
      "3. delete (Class: JpaPetTypeRepositoryImpl)\n",
      "   Cognitive: 1, Cyclomatic: 4, Diff: 3\n",
      "4. delete (Class: SpringDataPetTypeRepositoryImpl)\n",
      "   Cognitive: 1, Cyclomatic: 4, Diff: 3\n",
      "5. failingRequest (Class: OopsApi)\n",
      "   Cognitive: 6, Cyclomatic: 3, Diff: 3\n",
      "\n",
      "üíæ Updated dictionary with both complexity metrics saved to: enhanced_methods_with_all_complexity.json\n",
      "‚úÖ Enhanced dictionary now includes:\n",
      "  - method_name, parameters, return_type, class\n",
      "  - line_of_code\n",
      "  - cyclomatic_complexity\n",
      "  - cognitive_complexity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cognitive_complexity(function_body, method_name=\"\"):\n",
    "    \"\"\"\n",
    "    Calculate Cognitive Complexity for a given function body.\n",
    "    \n",
    "    Cognitive Complexity focuses on how difficult code is to understand.\n",
    "    Unlike Cyclomatic Complexity, it considers nesting levels and ignores certain constructs.\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return 0  # Base cognitive complexity for empty method\n",
    "    \n",
    "    function_body = str(function_body)\n",
    "    complexity = 0\n",
    "    nesting_level = 0\n",
    "    \n",
    "    # Keywords that increment cognitive complexity\n",
    "    increment_keywords = [\n",
    "        'if', 'while', 'for', 'do', 'switch', 'catch', \n",
    "        'goto', 'break', 'continue', 'forEach'\n",
    "    ]\n",
    "    \n",
    "    # Keywords that increase nesting but don't add base complexity\n",
    "    nesting_keywords = ['if', 'while', 'for', 'do', 'switch', 'try', 'catch']\n",
    "    \n",
    "    # Split into lines for analysis\n",
    "    lines = function_body.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line_stripped = line.strip().lower()\n",
    "        line_original = line.strip()\n",
    "        \n",
    "        # Count opening braces to track nesting level changes\n",
    "        open_braces = line_original.count('{')\n",
    "        close_braces = line_original.count('}')\n",
    "        \n",
    "        # Check for control flow keywords that add complexity\n",
    "        for keyword in increment_keywords:\n",
    "            import re\n",
    "            pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "            if re.search(pattern, line_stripped):\n",
    "                # Add base complexity + nesting level\n",
    "                if keyword in nesting_keywords:\n",
    "                    complexity += 1 + nesting_level\n",
    "                    nesting_level += 1  # Increase nesting for next statements\n",
    "                else:\n",
    "                    complexity += 1 + nesting_level\n",
    "        \n",
    "        # Count binary logical operators in the line\n",
    "        logical_and_count = len(re.findall(r'&&', line_original))\n",
    "        logical_or_count = len(re.findall(r'\\|\\|', line_original))\n",
    "        complexity += logical_and_count + logical_or_count\n",
    "        \n",
    "        # Check for recursion (method calling itself)\n",
    "        if method_name and method_name in line_original:\n",
    "            # Simple check for method call (method_name followed by parentheses)\n",
    "            if re.search(rf'\\b{re.escape(method_name)}\\s*\\(', line_original):\n",
    "                complexity += 1\n",
    "        \n",
    "        # Update nesting level based on braces\n",
    "        # Note: This is a simplified approach\n",
    "        if open_braces > close_braces:\n",
    "            nesting_level += (open_braces - close_braces)\n",
    "        elif close_braces > open_braces:\n",
    "            nesting_level = max(0, nesting_level - (close_braces - open_braces))\n",
    "    \n",
    "    return complexity\n",
    "\n",
    "# Calculate Cognitive Complexity for all methods and update the enhanced dictionary\n",
    "print(\"üîÑ Calculating Cognitive Complexity for all methods...\")\n",
    "\n",
    "# Check if enhanced_methods_dict_list exists\n",
    "if 'enhanced_methods_dict_list' not in globals():\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    # Create a copy to avoid modifying during iteration\n",
    "    updated_methods_list = []\n",
    "    \n",
    "    for i, method_entry in enumerate(enhanced_methods_dict_list):\n",
    "        # Get the original function body from ast_df for this method\n",
    "        method_name = method_entry['method_name']\n",
    "        class_name = method_entry['class']\n",
    "        \n",
    "        # Find the corresponding row in ast_df\n",
    "        matching_rows = ast_df[\n",
    "            (ast_df['Method Name'] == method_name) & \n",
    "            (ast_df['Class'] == class_name)\n",
    "        ]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            function_body = matching_rows.iloc[0]['Function Body']\n",
    "        else:\n",
    "            function_body = ''\n",
    "        \n",
    "        # Calculate cognitive complexity\n",
    "        cognitive_complexity = calculate_cognitive_complexity(function_body, method_name)\n",
    "        \n",
    "        # Create updated method entry with cognitive complexity\n",
    "        updated_method_entry = method_entry.copy()\n",
    "        updated_method_entry['cognitive_complexity'] = cognitive_complexity\n",
    "        \n",
    "        updated_methods_list.append(updated_method_entry)\n",
    "    \n",
    "    # Update the enhanced_methods_dict_list\n",
    "    enhanced_methods_dict_list = updated_methods_list\n",
    "    \n",
    "    print(f\"‚úÖ Updated {len(enhanced_methods_dict_list)} methods with Cognitive Complexity\")\n",
    "    \n",
    "    # Display statistics\n",
    "    cognitive_values = [method['cognitive_complexity'] for method in enhanced_methods_dict_list]\n",
    "    cyclomatic_values = [method['cyclomatic_complexity'] for method in enhanced_methods_dict_list]\n",
    "    \n",
    "    print(f\"\\nüìä Cognitive Complexity Statistics:\")\n",
    "    print(f\"Average Cognitive Complexity: {np.mean(cognitive_values):.2f}\")\n",
    "    print(f\"Median Cognitive Complexity: {np.median(cognitive_values):.2f}\")\n",
    "    print(f\"Min Cognitive Complexity: {min(cognitive_values)}\")\n",
    "    print(f\"Max Cognitive Complexity: {max(cognitive_values)}\")\n",
    "    print(f\"Standard Deviation: {np.std(cognitive_values):.2f}\")\n",
    "    \n",
    "    # Compare with Cyclomatic Complexity\n",
    "    print(f\"\\nüîÑ Comparison with Cyclomatic Complexity:\")\n",
    "    print(f\"Average CC: {np.mean(cyclomatic_values):.2f} vs Cognitive: {np.mean(cognitive_values):.2f}\")\n",
    "    print(f\"Correlation between CC and Cognitive: {np.corrcoef(cyclomatic_values, cognitive_values)[0,1]:.3f}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    cognitive_counts = Counter(cognitive_values)\n",
    "    print(f\"\\nüìà Cognitive Complexity Distribution (top 10):\")\n",
    "    for cc, count in cognitive_counts.most_common(10):\n",
    "        print(f\"  Cognitive {cc}: {count} methods ({count/len(cognitive_values)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample updated entries\n",
    "    print(f\"\\nüìã Sample updated entries with both complexities (first 5):\")\n",
    "    for i, method in enumerate(enhanced_methods_dict_list[:5]):\n",
    "        print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "        print(f\"   Class: {method['class']}\")\n",
    "        print(f\"   LOC: {method['line_of_code']}\")\n",
    "        print(f\"   Cyclomatic Complexity: {method['cyclomatic_complexity']}\")\n",
    "        print(f\"   Cognitive Complexity: {method['cognitive_complexity']}\")\n",
    "        print(\"   ---\")\n",
    "    \n",
    "    # Show methods with highest cognitive complexity\n",
    "    sorted_by_cognitive = sorted(enhanced_methods_dict_list, \n",
    "                               key=lambda x: x['cognitive_complexity'], \n",
    "                               reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 methods by Cognitive Complexity:\")\n",
    "    for i, method in enumerate(sorted_by_cognitive[:10]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   Cognitive: {method['cognitive_complexity']}, Cyclomatic: {method['cyclomatic_complexity']}, LOC: {method['line_of_code']}\")\n",
    "    \n",
    "    # Show methods where Cognitive and Cyclomatic differ significantly\n",
    "    complexity_diff = []\n",
    "    for method in enhanced_methods_dict_list:\n",
    "        diff = abs(method['cognitive_complexity'] - method['cyclomatic_complexity'])\n",
    "        complexity_diff.append((method, diff))\n",
    "    \n",
    "    complexity_diff.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Top 5 methods with largest Cognitive vs Cyclomatic difference:\")\n",
    "    for i, (method, diff) in enumerate(complexity_diff[:5]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   Cognitive: {method['cognitive_complexity']}, Cyclomatic: {method['cyclomatic_complexity']}, Diff: {diff}\")\n",
    "    \n",
    "    # Update the JSON file with both complexity metrics\n",
    "    final_output_filename = \"enhanced_methods_with_all_complexity.json\"\n",
    "    with open(final_output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Updated dictionary with both complexity metrics saved to: {final_output_filename}\")\n",
    "    print(f\"‚úÖ Enhanced dictionary now includes:\")\n",
    "    print(f\"  - method_name, parameters, return_type, class\")\n",
    "    print(f\"  - line_of_code\")\n",
    "    print(f\"  - cyclomatic_complexity\")\n",
    "    print(f\"  - cognitive_complexity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db2b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
