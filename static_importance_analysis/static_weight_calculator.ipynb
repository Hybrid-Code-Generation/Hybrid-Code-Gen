{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c89ab96",
   "metadata": {},
   "source": [
    "# Static Importance Index Calculator for Java Methods\n",
    "\n",
    "This notebook computes static importance indices for Java methods using both **Knowledge Graph** data from Neo4j and **AST** metadata. The goal is to create normalized weights that will be used for method retrieval in a hybrid RAG system for code generation.\n",
    "\n",
    "## Metrics Computed:\n",
    "- **Code Complexity**: LOC, Cyclomatic Complexity, Cognitive Complexity, Halstead Effort\n",
    "- **Graph Centrality**: Degree Centrality, Betweenness Centrality, Eigenvector Centrality\n",
    "- **Method Dependencies**: Fan-in, Fan-out \n",
    "- **Parameter Analysis**: Number of parameters, parameter type complexity, return type complexity\n",
    "\n",
    "## Data Sources:\n",
    "- **Neo4j Knowledge Graph**: `http://4.187.169.27:7474/browser/`\n",
    "- **AST Data**: `../AST/java_parsed.csv`\n",
    "- **Target Project**: Library Management System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9c41c",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Libraries\n",
    "\n",
    "Import all necessary libraries for Neo4j connectivity, data analysis, graph operations, and complexity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8304f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Tree-sitter available: True\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Neo4j connection\n",
    "from neo4j import GraphDatabase\n",
    "import logging\n",
    "\n",
    "# Graph analysis\n",
    "import networkx as nx\n",
    "\n",
    "# For complexity calculations\n",
    "import ast\n",
    "import math\n",
    "from typing import Dict, List, Tuple, Set\n",
    "import json\n",
    "\n",
    "# For Java AST parsing\n",
    "try:\n",
    "    from tree_sitter import Language, Parser\n",
    "    from tree_sitter_languages import get_language\n",
    "    TREE_SITTER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"tree-sitter not available. Some complexity metrics will use simplified calculations.\")\n",
    "    TREE_SITTER_AVAILABLE = False\n",
    "\n",
    "# Setup plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Tree-sitter available: {TREE_SITTER_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9be61d",
   "metadata": {},
   "source": [
    "## 2. Connect to Neo4j Knowledge Graph\n",
    "\n",
    "Establish connection to the Neo4j database containing the Java knowledge graph and verify connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee96dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Neo4j connection successful!\n",
      "Result: Connection successful\n",
      "\n",
      "üìä Database Statistics:\n",
      "Total nodes: 1,327\n",
      "Total relationships: 6,412\n",
      "Available node labels: ['Import', 'Package', 'Class', 'Constructor', 'Parameter', 'Method', 'Type', 'Annotation', 'Variable', 'Interface', 'Field']\n",
      "Available relationship types: ['INHERITS', 'HAS_CONSTRUCTOR', 'HAS_PARAMETER', 'HAS_METHOD', 'RETURNS', 'HAS_ANNOTATION', 'USES', 'CALLS', 'IMPLEMENTS', 'HAS_FIELD', 'CALLED_BY', 'BELONGS_TO']\n",
      "\n",
      "üîç Call Relationship Analysis:\n",
      "CALLS relationships: 1,900\n",
      "CALLED_BY relationships: 1,900\n"
     ]
    }
   ],
   "source": [
    "# Neo4j connection configuration\n",
    "NEO4J_URI = \"bolt://172.203.167.64:7687\"  # Updated to new Neo4j instance\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"C{&K1r.eZ9*4\"  # Updated password\n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri, username, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "        \n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters)\n",
    "            return [record for record in result]\n",
    "\n",
    "# Initialize connection\n",
    "neo4j_conn = Neo4jConnection(NEO4J_URI, NEO4J_USERNAME, NEO4J_PASSWORD)\n",
    "\n",
    "# Test connection and get database info\n",
    "try:\n",
    "    # Test basic connectivity\n",
    "    test_result = neo4j_conn.query(\"RETURN 'Connection successful' as message\")\n",
    "    print(\"‚úÖ Neo4j connection successful!\")\n",
    "    print(f\"Result: {test_result[0]['message']}\")\n",
    "    \n",
    "    # Get database statistics\n",
    "    node_count = neo4j_conn.query(\"MATCH (n) RETURN count(n) as count\")[0]['count']\n",
    "    rel_count = neo4j_conn.query(\"MATCH ()-[r]->() RETURN count(r) as count\")[0]['count']\n",
    "    \n",
    "    print(f\"\\nüìä Database Statistics:\")\n",
    "    print(f\"Total nodes: {node_count:,}\")\n",
    "    print(f\"Total relationships: {rel_count:,}\")\n",
    "    \n",
    "    # Get available node labels\n",
    "    labels_result = neo4j_conn.query(\"CALL db.labels()\")\n",
    "    labels = [record['label'] for record in labels_result]\n",
    "    print(f\"Available node labels: {labels}\")\n",
    "    \n",
    "    # Get available relationship types\n",
    "    rel_types_result = neo4j_conn.query(\"CALL db.relationshipTypes()\")\n",
    "    rel_types = [record['relationshipType'] for record in rel_types_result]\n",
    "    print(f\"Available relationship types: {rel_types}\")\n",
    "    \n",
    "    # Specifically check for CALLS and CALLED_BY relationships\n",
    "    calls_count = neo4j_conn.query(\"MATCH ()-[r:CALLS]->() RETURN count(r) as count\")[0]['count']\n",
    "    called_by_count = neo4j_conn.query(\"MATCH ()-[r:CALLED_BY]->() RETURN count(r) as count\")[0]['count']\n",
    "    print(f\"\\nüîç Call Relationship Analysis:\")\n",
    "    print(f\"CALLS relationships: {calls_count:,}\")\n",
    "    print(f\"CALLED_BY relationships: {called_by_count:,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Connection failed: {e}\")\n",
    "    print(\"Please check the Neo4j server status and credentials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231b25c1",
   "metadata": {},
   "source": [
    "## 3. Load AST Data from CSV\n",
    "\n",
    "Load the existing AST parsed data and perform initial exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8d3546c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded AST data: 786 methods found\n",
      "\n",
      "üìä AST Data Overview:\n",
      "Shape: (786, 10)\n",
      "Columns: ['FilePath', 'Package', 'Class', 'Method Name', 'Return Type', 'Parameters', 'Function Body', 'Throws', 'Modifiers', 'Generics']\n",
      "\n",
      "üîç Sample Data:\n",
      "                                            FilePath  Package  \\\n",
      "0  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "1  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "2  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "3  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "4  C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\s...      NaN   \n",
      "\n",
      "                    Class                Method Name             Return Type  \\\n",
      "0  MavenWrapperDownloader                       main                    void   \n",
      "1  MavenWrapperDownloader        downloadFileFromURL                    void   \n",
      "2  MavenWrapperDownloader  getPasswordAuthentication  PasswordAuthentication   \n",
      "3    PetClinicApplication                       main                    void   \n",
      "4           SwaggerConfig              customOpenAPI                 OpenAPI   \n",
      "\n",
      "                           Parameters  \\\n",
      "0                         String args   \n",
      "1  String urlString, File destination   \n",
      "2                                 NaN   \n",
      "3                       String[] args   \n",
      "4                                 NaN   \n",
      "\n",
      "                                       Function Body            Throws  \\\n",
      "0  {\\n        System.out.println(\"- Downloader st...               NaN   \n",
      "1  {\\n        if (System.getenv(\"MVNW_USERNAME\") ...  throws Exception   \n",
      "2  {\\n                    return new PasswordAuth...               NaN   \n",
      "3  {\\n\\t\\tSpringApplication.run(PetClinicApplicat...               NaN   \n",
      "4  {\\n        return new OpenAPI()\\n            ....               NaN   \n",
      "\n",
      "             Modifiers Generics  \n",
      "0        public static      NaN  \n",
      "1       private static      NaN  \n",
      "2  @Override protected      NaN  \n",
      "3        public static      NaN  \n",
      "4                @Bean      NaN  \n",
      "\n",
      "‚ùì Missing Values:\n",
      "Package          786\n",
      "Parameters       307\n",
      "Function Body    103\n",
      "Throws           567\n",
      "Modifiers         91\n",
      "Generics         784\n",
      "dtype: int64\n",
      "\n",
      "üìà Basic Statistics:\n",
      "Unique classes: 118\n",
      "Unique packages: 0\n",
      "Methods with function body: 683\n",
      "\n",
      "üèóÔ∏è Top 10 Classes by Method Count:\n",
      "Class\n",
      "AbstractClinicServiceTests    35\n",
      "ClinicServiceImpl             30\n",
      "ClinicService                 29\n",
      "OwnerDto                      26\n",
      "OwnerRestControllerTests      25\n",
      "PetDto                        23\n",
      "ProblemDetailDto              23\n",
      "OwnerFieldsDto                19\n",
      "UserDto                       17\n",
      "VetDto                        17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load AST data from CSV\n",
    "ast_file_path = \"../methods.csv\"\n",
    "\n",
    "try:\n",
    "    ast_df = pd.read_csv(ast_file_path)\n",
    "    print(f\"‚úÖ Successfully loaded AST data: {len(ast_df)} methods found\")\n",
    "    \n",
    "    # Basic data exploration\n",
    "    print(f\"\\nüìä AST Data Overview:\")\n",
    "    print(f\"Shape: {ast_df.shape}\")\n",
    "    print(f\"Columns: {list(ast_df.columns)}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(f\"\\nüîç Sample Data:\")\n",
    "    print(ast_df.head())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\n‚ùì Missing Values:\")\n",
    "    missing_counts = ast_df.isnull().sum()\n",
    "    print(missing_counts[missing_counts > 0])\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìà Basic Statistics:\")\n",
    "    print(f\"Unique classes: {ast_df['Class'].nunique()}\")\n",
    "    print(f\"Unique packages: {ast_df['Package'].nunique()}\")\n",
    "    print(f\"Methods with function body: {ast_df['Function Body'].notna().sum()}\")\n",
    "    \n",
    "    # Method distribution by class\n",
    "    method_counts = ast_df['Class'].value_counts()\n",
    "    print(f\"\\nüèóÔ∏è Top 10 Classes by Method Count:\")\n",
    "    print(method_counts.head(10))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Could not find AST file at: {ast_file_path}\")\n",
    "    print(\"Please ensure the AST parsing has been completed and the file exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading AST data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5cc522",
   "metadata": {},
   "source": [
    "## 4. Extract Method Information from Knowledge Graph\n",
    "\n",
    "Query the Neo4j graph to extract method nodes and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c2f9b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Extracting method nodes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 4, column: 12, offset: 68} for query: '\\n    MATCH (m:Method)\\n    RETURN m.name as method_name, \\n           id(m) as node_id,\\n           m.depth as depth,\\n           labels(m) as labels\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 475 method nodes\n",
      "üîÑ Extracting CALLS and CALLED_BY relationships...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 6, column: 12, offset: 172} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 7, column: 12, offset: 204} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 13, column: 12, offset: 417} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 14, column: 12, offset: 449} for query: \"\\n    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLS' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    UNION ALL\\n    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\\n    RETURN m1.name as source_method,\\n           m2.name as target_method,\\n           'CALLED_BY' as relationship_type,\\n           id(m1) as source_id,\\n           id(m2) as target_id\\n    \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3800 call relationships\n",
      "üìä Relationship type distribution:\n",
      "  CALLS: 1900\n",
      "  CALLED_BY: 1900\n",
      "üîÑ Extracting method-class relationships...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 5, column: 12, offset: 126} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 6, column: 12, offset: 156} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 11, column: 12, offset: 314} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 12, column: 12, offset: 344} for query: '\\n    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    UNION ALL\\n    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\\n    RETURN c.name as class_name,\\n           m.name as method_name,\\n           id(c) as class_id,\\n           id(m) as method_id\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 922 method-class relationships\n",
      "üîÑ Extracting method parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 5, column: 12, offset: 123} for query: '\\n    MATCH (m:Method)-[r:HAS_PARAMETER]->(p)\\n    RETURN m.name as method_name,\\n           p.name as param_name,\\n           id(m) as method_id,\\n           id(p) as param_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function: `id`.} {position: line: 6, column: 12, offset: 154} for query: '\\n    MATCH (m:Method)-[r:HAS_PARAMETER]->(p)\\n    RETURN m.name as method_name,\\n           p.name as param_name,\\n           id(m) as method_id,\\n           id(p) as param_id\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 method parameters\n",
      "\n",
      "üîç Call Graph Analysis:\n",
      "Unique calling methods: 457\n",
      "Unique called methods: 457\n",
      "\n",
      "üìã Sample call relationships:\n",
      "  toString -CALLS-> getId\n",
      "  toString -CALLS-> isNew\n",
      "  toString -CALLS-> getLastName\n",
      "  toString -CALLS-> getFirstName\n",
      "  toString -CALLS-> append\n",
      "  toString -CALLS-> toString\n",
      "  toString -CALLS-> getName\n",
      "  getPets -CALLS-> unmodifiableList\n",
      "  getPets -CALLS-> sort\n",
      "  getPets -CALLS-> getPetsInternal\n",
      "\n",
      "‚úÖ Knowledge Graph data extracted successfully!\n",
      "\n",
      "üìä METHODS Sample:\n",
      "   method_name  node_id  depth    labels\n",
      "0  toVisitsDto        1      1  [Method]\n",
      "1        getId       15      1  [Method]\n",
      "2        setId       17      1  [Method]\n",
      "3        isNew       20      1  [Method]\n",
      "4      getName       28      1  [Method]\n",
      "Shape: (475, 4)\n",
      "\n",
      "üìä RELATIONSHIPS Sample:\n",
      "  source_method target_method relationship_type  source_id  target_id\n",
      "0      toString         getId             CALLS         31         15\n",
      "1      toString         isNew             CALLS         31         20\n",
      "2      toString   getLastName             CALLS         31         87\n",
      "3      toString  getFirstName             CALLS         31         86\n",
      "4      toString        append             CALLS         31         85\n",
      "Shape: (3800, 5)\n",
      "\n",
      "üìä METHOD_CLASS Sample:\n",
      "    class_name method_name  class_id  method_id\n",
      "0   BaseEntity       isNew        11         20\n",
      "1   BaseEntity       setId        11         17\n",
      "2   BaseEntity       getId        11         15\n",
      "3  NamedEntity    toString        25         31\n",
      "4  NamedEntity     setName        25       1111\n",
      "Shape: (922, 4)\n",
      "\n",
      "üìä METHOD_PARAMS Sample:\n",
      "No data found\n"
     ]
    }
   ],
   "source": [
    "# Extract method information from Knowledge Graph\n",
    "def extract_kg_data():\n",
    "    \"\"\"Extract all relevant data from the knowledge graph, focusing on CALLS and CALLED_BY relationships\"\"\"\n",
    "    \n",
    "    # Get all method nodes\n",
    "    methods_query = \"\"\"\n",
    "    MATCH (m:Method)\n",
    "    RETURN m.name as method_name, \n",
    "           id(m) as node_id,\n",
    "           m.depth as depth,\n",
    "           labels(m) as labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get CALLS and CALLED_BY relationships specifically\n",
    "    calls_relationships_query = \"\"\"\n",
    "    MATCH (m1:Method)-[r:CALLS]->(m2:Method)\n",
    "    RETURN m1.name as source_method,\n",
    "           m2.name as target_method,\n",
    "           'CALLS' as relationship_type,\n",
    "           id(m1) as source_id,\n",
    "           id(m2) as target_id\n",
    "    UNION ALL\n",
    "    MATCH (m1:Method)-[r:CALLED_BY]->(m2:Method)\n",
    "    RETURN m1.name as source_method,\n",
    "           m2.name as target_method,\n",
    "           'CALLED_BY' as relationship_type,\n",
    "           id(m1) as source_id,\n",
    "           id(m2) as target_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get method-class relationships\n",
    "    method_class_query = \"\"\"\n",
    "    MATCH (c:Class)-[r:HAS_METHOD]->(m:Method)\n",
    "    RETURN c.name as class_name,\n",
    "           m.name as method_name,\n",
    "           id(c) as class_id,\n",
    "           id(m) as method_id\n",
    "    UNION ALL\n",
    "    MATCH (m:Method)-[r:BELONGS_TO]->(c:Class)\n",
    "    RETURN c.name as class_name,\n",
    "           m.name as method_name,\n",
    "           id(c) as class_id,\n",
    "           id(m) as method_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get method parameters\n",
    "    method_params_query = \"\"\"\n",
    "    MATCH (m:Method)-[r:HAS_PARAMETER]->(p)\n",
    "    RETURN m.name as method_name,\n",
    "           p.name as param_name,\n",
    "           id(m) as method_id,\n",
    "           id(p) as param_id\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Extracting method nodes...\")\n",
    "        methods_data = neo4j_conn.query(methods_query)\n",
    "        methods_df = pd.DataFrame([dict(record) for record in methods_data])\n",
    "        print(f\"Found {len(methods_df)} method nodes\")\n",
    "        \n",
    "        print(\"üîÑ Extracting CALLS and CALLED_BY relationships...\")\n",
    "        relationships_data = neo4j_conn.query(calls_relationships_query)\n",
    "        relationships_df = pd.DataFrame([dict(record) for record in relationships_data])\n",
    "        print(f\"Found {len(relationships_df)} call relationships\")\n",
    "        \n",
    "        # Analyze the distribution of relationship types\n",
    "        if not relationships_df.empty:\n",
    "            rel_distribution = relationships_df['relationship_type'].value_counts()\n",
    "            print(f\"üìä Relationship type distribution:\")\n",
    "            for rel_type, count in rel_distribution.items():\n",
    "                print(f\"  {rel_type}: {count}\")\n",
    "        \n",
    "        print(\"üîÑ Extracting method-class relationships...\")\n",
    "        method_class_data = neo4j_conn.query(method_class_query)\n",
    "        method_class_df = pd.DataFrame([dict(record) for record in method_class_data])\n",
    "        print(f\"Found {len(method_class_df)} method-class relationships\")\n",
    "        \n",
    "        print(\"üîÑ Extracting method parameters...\")\n",
    "        method_params_data = neo4j_conn.query(method_params_query)\n",
    "        method_params_df = pd.DataFrame([dict(record) for record in method_params_data])\n",
    "        print(f\"Found {len(method_params_df)} method parameters\")\n",
    "        \n",
    "        # Additional analysis of the call graph structure\n",
    "        if not relationships_df.empty:\n",
    "            unique_callers = relationships_df['source_method'].nunique()\n",
    "            unique_callees = relationships_df['target_method'].nunique()\n",
    "            print(f\"\\nüîç Call Graph Analysis:\")\n",
    "            print(f\"Unique calling methods: {unique_callers}\")\n",
    "            print(f\"Unique called methods: {unique_callees}\")\n",
    "            \n",
    "            # Show sample relationships\n",
    "            print(f\"\\nüìã Sample call relationships:\")\n",
    "            sample_rels = relationships_df.head(10)\n",
    "            for _, row in sample_rels.iterrows():\n",
    "                print(f\"  {row['source_method']} -{row['relationship_type']}-> {row['target_method']}\")\n",
    "        \n",
    "        return {\n",
    "            'methods': methods_df,\n",
    "            'relationships': relationships_df,\n",
    "            'method_class': method_class_df,\n",
    "            'method_params': method_params_df\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting KG data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Extract the data\n",
    "kg_data = extract_kg_data()\n",
    "\n",
    "if kg_data:\n",
    "    print(\"\\n‚úÖ Knowledge Graph data extracted successfully!\")\n",
    "    \n",
    "    # Display sample data\n",
    "    for key, df in kg_data.items():\n",
    "        print(f\"\\nüìä {key.upper()} Sample:\")\n",
    "        if not df.empty:\n",
    "            print(df.head())\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "        else:\n",
    "            print(\"No data found\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to extract knowledge graph data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a597e58",
   "metadata": {},
   "source": [
    "## 5. Generate Method Dictionary with Line of Code Counts\n",
    "\n",
    "This section creates a dictionary (list of dictionaries) containing each method name and its corresponding line of code count. The line of code count is calculated by:\n",
    "\n",
    "1. Parsing the function body from the CSV data\n",
    "2. Splitting into individual lines\n",
    "3. Filtering out empty lines and comments\n",
    "4. Counting the remaining code lines\n",
    "\n",
    "The output format will be:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"method_name\": \"methodA\",\n",
    "        \"line_of_code\": 40\n",
    "    },\n",
    "    {\n",
    "        \"method_name\": \"methodB\", \n",
    "        \"line_of_code\": 20\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "746a8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ extract_lines_of_code function defined successfully!\n",
      "üìù Test function LOC: 1\n",
      "Function is ready to use!\n"
     ]
    }
   ],
   "source": [
    "def extract_lines_of_code(function_body):\n",
    "    \"\"\"\n",
    "    Extract the number of lines of code from a function body string.\n",
    "    Handles various edge cases and formats.\n",
    "    \n",
    "    Args:\n",
    "        function_body (str): The function body code as a string\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of lines of code (excluding empty lines and comments)\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return 0\n",
    "    \n",
    "    # Convert to string if not already\n",
    "    function_body = str(function_body)\n",
    "    \n",
    "    # Split by lines and filter out empty lines and comments\n",
    "    lines = function_body.split('\\\\n')\n",
    "    \n",
    "    # Count non-empty lines (excluding pure whitespace and single-line comments)\n",
    "    code_lines = []\n",
    "    for line in lines:\n",
    "        stripped_line = line.strip()\n",
    "        # Skip empty lines\n",
    "        if not stripped_line:\n",
    "            continue\n",
    "        # Skip single-line comments (// or /* ... */)\n",
    "        if stripped_line.startswith('//') or (stripped_line.startswith('/*') and stripped_line.endswith('*/')):\n",
    "            continue\n",
    "        code_lines.append(line)\n",
    "    \n",
    "    return len(code_lines)\n",
    "\n",
    "# Test the function with a sample\n",
    "print(\"‚úÖ extract_lines_of_code function defined successfully!\")\n",
    "\n",
    "# Test with a sample function body\n",
    "test_function_body = \"\"\"\n",
    "public void testMethod() {\n",
    "    // This is a comment\n",
    "    int x = 5;\n",
    "    if (x > 0) {\n",
    "        System.out.println(\"Positive\");\n",
    "    }\n",
    "    /* Another comment */\n",
    "    return;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "test_loc = extract_lines_of_code(test_function_body)\n",
    "print(f\"üìù Test function LOC: {test_loc}\")\n",
    "print(\"Function is ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "befa99b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating enhanced method dictionary with unique identifiers...\n",
      "Available columns in ast_df: ['FilePath', 'Package', 'Class', 'Method Name', 'Return Type', 'Parameters', 'Function Body', 'Throws', 'Modifiers', 'Generics']\n",
      "\n",
      "Sample row to understand data structure:\n",
      "  FilePath: C:\\repos\\Hybrid-Code-Gen\\javarepoparser\\temp\\spring-petclinic-rest\\.mvn\\wrapper\\MavenWrapperDownloader.java\n",
      "  Package: nan\n",
      "  Class: MavenWrapperDownloader\n",
      "  Method Name: main\n",
      "  Return Type: void\n",
      "  Parameters: String args\n",
      "  Function Body: {\\n        System.out.println(\"- Downloader started\");\\n        File baseDirectory = new File(args[0]);\\n        System.out.println(\"- Using base directory: \" + baseDirectory.getAbsolutePath());\\n\\n        // If the maven-wrapper.properties exists, read it and check if it contains a custom\\n        // wrapperUrl parameter.\\n        File mavenWrapperPropertyFile = new File(baseDirectory, MAVEN_WRAPPER_PROPERTIES_PATH);\\n        String url = DEFAULT_DOWNLOAD_URL;\\n        if(mavenWrapperPropertyFile.exists()) {\\n            FileInputStream mavenWrapperPropertyFileInputStream = null;\\n            try {\\n                mavenWrapperPropertyFileInputStream = new FileInputStream(mavenWrapperPropertyFile);\\n                Properties mavenWrapperProperties = new Properties();\\n                mavenWrapperProperties.load(mavenWrapperPropertyFileInputStream);\\n                url = mavenWrapperProperties.getProperty(PROPERTY_NAME_WRAPPER_URL, url);\\n            } catch (IOException e) {\\n                System.out.println(\"- ERROR loading '\" + MAVEN_WRAPPER_PROPERTIES_PATH + \"'\");\\n            } finally {\\n                try {\\n                    if(mavenWrapperPropertyFileInputStream != null) {\\n                        mavenWrapperPropertyFileInputStream.close();\\n                    }\\n                } catch (IOException e) {\\n                    // Ignore ...\\n                }\\n            }\\n        }\\n        System.out.println(\"- Downloading from: \" + url);\\n\\n        File outputFile = new File(baseDirectory.getAbsolutePath(), MAVEN_WRAPPER_JAR_PATH);\\n        if(!outputFile.getParentFile().exists()) {\\n            if(!outputFile.getParentFile().mkdirs()) {\\n                System.out.println(\\n                        \"- ERROR creating output directory '\" + outputFile.getParentFile().getAbsolutePath() + \"'\");\\n            }\\n        }\\n        System.out.println(\"- Downloading to: \" + outputFile.getAbsolutePath());\\n        try {\\n            downloadFileFromURL(url, outputFile);\\n            System.out.println(\"Done\");\\n            System.exit(0);\\n        } catch (Throwable e) {\\n            System.out.println(\"- Error downloading\");\\n            e.printStackTrace();\\n            System.exit(1);\\n        }\\n    }\n",
      "  Throws: nan\n",
      "  Modifiers: public static\n",
      "  Generics: nan\n",
      "‚úÖ Generated enhanced dictionary for 786 methods\n",
      "\n",
      "üìã Sample enhanced entries (first 10):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   Parameters: String args\n",
      "   Return Type: void\n",
      "   LOC: 43\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   Parameters: String urlString, File destination\n",
      "   Return Type: void\n",
      "   LOC: 19\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   Parameters: \n",
      "   Return Type: PasswordAuthentication\n",
      "   LOC: 3\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   Parameters: String[] args\n",
      "   Return Type: void\n",
      "   LOC: 3\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   Parameters: \n",
      "   Return Type: OpenAPI\n",
      "   LOC: 13\n",
      "   ---\n",
      "6. Method: 'swaggerContact'\n",
      "   Class: SwaggerConfig\n",
      "   Parameters: \n",
      "   Return Type: Contact\n",
      "   LOC: 7\n",
      "   ---\n",
      "7. Method: 'swaggerLicense'\n",
      "   Class: SwaggerConfig\n",
      "   Parameters: \n",
      "   Return Type: License\n",
      "   LOC: 7\n",
      "   ---\n",
      "8. Method: 'toOwnerDto'\n",
      "   Class: OwnerMapper\n",
      "   Parameters: Owner owner\n",
      "   Return Type: OwnerDto\n",
      "   LOC: 0\n",
      "   ---\n",
      "9. Method: 'toOwner'\n",
      "   Class: OwnerMapper\n",
      "   Parameters: OwnerDto ownerDto\n",
      "   Return Type: Owner\n",
      "   LOC: 0\n",
      "   ---\n",
      "10. Method: 'toOwner'\n",
      "   Class: OwnerMapper\n",
      "   Parameters: OwnerFieldsDto ownerDto\n",
      "   Return Type: Owner\n",
      "   LOC: 0\n",
      "   ---\n",
      "\n",
      "üìä Method Name Analysis:\n",
      "Total unique method names: 377\n",
      "Method names with duplicates: 155\n",
      "Top 10 most common method names:\n",
      "  'delete': 26 occurrences\n",
      "  'save': 21 occurrences\n",
      "  'toString': 19 occurrences\n",
      "  'findById': 19 occurrences\n",
      "  'findAll': 18 occurrences\n",
      "  'equals': 15 occurrences\n",
      "  'hashCode': 15 occurrences\n",
      "  'toIndentedString': 15 occurrences\n",
      "  'getName': 8 occurrences\n",
      "  'setName': 8 occurrences\n",
      "\n",
      "üîç Unique Method Signature Analysis:\n",
      "Total methods: 786\n",
      "Unique method signatures: 785\n",
      "Duplicate signatures found: 1\n",
      "Sample duplicate signatures:\n",
      "  1. mapRow in JdbcVetRepositoryImpl with params: ResultSet rs, int row\n",
      "\n",
      "üíæ Enhanced dictionary saved to: enhanced_methods_dictionary.json\n",
      "‚úÖ Enhanced dictionary is available in the 'enhanced_methods_dict_list' variable\n",
      "\n",
      "Format: List of dictionaries with keys:\n",
      "  - 'method_name': Method name\n",
      "  - 'parameters': Method parameters\n",
      "  - 'return_type': Return type\n",
      "  - 'class': Class containing the method\n",
      "  - 'line_of_code': Lines of code count\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Method Dictionary Generation with Unique Identifiers\n",
    "print(\"üîÑ Generating enhanced method dictionary with unique identifiers...\")\n",
    "\n",
    "# First, let's examine the available columns to understand the data structure\n",
    "print(f\"Available columns in ast_df: {list(ast_df.columns)}\")\n",
    "print(f\"\\nSample row to understand data structure:\")\n",
    "if len(ast_df) > 0:\n",
    "    sample_row = ast_df.iloc[0]\n",
    "    for col in ast_df.columns:\n",
    "        print(f\"  {col}: {sample_row[col]}\")\n",
    "\n",
    "# Enhanced dictionary generation with unique method identification\n",
    "enhanced_methods_dict_list = []\n",
    "\n",
    "for index, row in ast_df.iterrows():\n",
    "    # Extract all required fields for unique identification\n",
    "    method_name = row.get('Method Name', row.get('Method', ''))\n",
    "    parameters = row.get('Parameters', row.get('Parameter', ''))\n",
    "    return_type = row.get('Return Type', row.get('ReturnType', ''))\n",
    "    class_name = row.get('Class', row.get('ClassName', ''))\n",
    "    function_body = row.get('Function Body', '')\n",
    "    \n",
    "    # Calculate lines of code\n",
    "    loc = extract_lines_of_code(function_body)\n",
    "    \n",
    "    # Clean up the data - handle NaN/null values\n",
    "    method_name = str(method_name) if pd.notna(method_name) else \"\"\n",
    "    parameters = str(parameters) if pd.notna(parameters) else \"\"\n",
    "    return_type = str(return_type) if pd.notna(return_type) else \"\"\n",
    "    class_name = str(class_name) if pd.notna(class_name) else \"\"\n",
    "    \n",
    "    # Create enhanced dictionary entry with unique identifiers\n",
    "    method_entry = {\n",
    "        \"method_name\": method_name,\n",
    "        \"parameters\": parameters,\n",
    "        \"return_type\": return_type,\n",
    "        \"class\": class_name,\n",
    "        \"function_body\": function_body,\n",
    "        \"line_of_code\": loc\n",
    "    }\n",
    "    enhanced_methods_dict_list.append(method_entry)\n",
    "\n",
    "print(f\"‚úÖ Generated enhanced dictionary for {len(enhanced_methods_dict_list)} methods\")\n",
    "\n",
    "# Display first 10 entries as sample\n",
    "print(f\"\\nüìã Sample enhanced entries (first 10):\")\n",
    "for i, method in enumerate(enhanced_methods_dict_list[:10]):\n",
    "    print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "    print(f\"   Class: {method['class']}\")\n",
    "    print(f\"   Parameters: {method['parameters']}\")\n",
    "    print(f\"   Return Type: {method['return_type']}\")\n",
    "    print(f\"   LOC: {method['line_of_code']}\")\n",
    "    print(\"   ---\")\n",
    "\n",
    "# Analyze method name duplicates\n",
    "method_names = [method['method_name'] for method in enhanced_methods_dict_list]\n",
    "method_name_counts = Counter(method_names)\n",
    "duplicates = {name: count for name, count in method_name_counts.items() if count > 1}\n",
    "\n",
    "print(f\"\\nüìä Method Name Analysis:\")\n",
    "print(f\"Total unique method names: {len(method_name_counts)}\")\n",
    "print(f\"Method names with duplicates: {len(duplicates)}\")\n",
    "if duplicates:\n",
    "    print(f\"Top 10 most common method names:\")\n",
    "    for name, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"  '{name}': {count} occurrences\")\n",
    "\n",
    "# Check for truly unique methods (considering all 4 identifiers)\n",
    "unique_signatures = set()\n",
    "duplicate_signatures = []\n",
    "\n",
    "for method in enhanced_methods_dict_list:\n",
    "    signature = (method['method_name'], method['parameters'], method['return_type'], method['class'])\n",
    "    if signature in unique_signatures:\n",
    "        duplicate_signatures.append(signature)\n",
    "    else:\n",
    "        unique_signatures.add(signature)\n",
    "\n",
    "print(f\"\\nüîç Unique Method Signature Analysis:\")\n",
    "print(f\"Total methods: {len(enhanced_methods_dict_list)}\")\n",
    "print(f\"Unique method signatures: {len(unique_signatures)}\")\n",
    "print(f\"Duplicate signatures found: {len(duplicate_signatures)}\")\n",
    "\n",
    "if duplicate_signatures:\n",
    "    print(f\"Sample duplicate signatures:\")\n",
    "    for i, sig in enumerate(duplicate_signatures[:5]):\n",
    "        print(f\"  {i+1}. {sig[0]} in {sig[3]} with params: {sig[1]}\")\n",
    "\n",
    "# Save enhanced dictionary to JSON file\n",
    "enhanced_output_filename = \"enhanced_methods_dictionary.json\"\n",
    "with open(enhanced_output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nüíæ Enhanced dictionary saved to: {enhanced_output_filename}\")\n",
    "print(f\"‚úÖ Enhanced dictionary is available in the 'enhanced_methods_dict_list' variable\")\n",
    "print(f\"\\nFormat: List of dictionaries with keys:\")\n",
    "print(f\"  - 'method_name': Method name\")\n",
    "print(f\"  - 'parameters': Method parameters\") \n",
    "print(f\"  - 'return_type': Return type\")\n",
    "print(f\"  - 'class': Class containing the method\")\n",
    "print(f\"  - 'line_of_code': Lines of code count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4848fbf9",
   "metadata": {},
   "source": [
    "## 6. Add Cyclomatic Complexity to Method Dictionary\n",
    "\n",
    "Calculate Cyclomatic Complexity for each method and add it to the enhanced method dictionary. Cyclomatic Complexity measures the number of linearly independent paths through a program's source code.\n",
    "\n",
    "**Formula**: CC = E - N + 2P\n",
    "- E = number of edges in the control flow graph\n",
    "- N = number of nodes in the control flow graph  \n",
    "- P = number of connected components\n",
    "\n",
    "**Simplified Calculation**: Count decision points (if, while, for, switch, etc.) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb385c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Calculating Cyclomatic Complexity for all methods...\n",
      "‚úÖ Updated 786 methods with Cyclomatic Complexity\n",
      "\n",
      "üìä Cyclomatic Complexity Statistics:\n",
      "Average CC: 1.59\n",
      "Median CC: 1.00\n",
      "Min CC: 1\n",
      "Max CC: 10\n",
      "Standard Deviation: 1.32\n",
      "\n",
      "üìà Complexity Distribution (top 10):\n",
      "  CC 1: 570 methods (72.5%)\n",
      "  CC 2: 127 methods (16.2%)\n",
      "  CC 3: 33 methods (4.2%)\n",
      "  CC 6: 29 methods (3.7%)\n",
      "  CC 4: 13 methods (1.7%)\n",
      "  CC 5: 6 methods (0.8%)\n",
      "  CC 7: 3 methods (0.4%)\n",
      "  CC 10: 2 methods (0.3%)\n",
      "  CC 9: 2 methods (0.3%)\n",
      "  CC 8: 1 methods (0.1%)\n",
      "\n",
      "üìã Sample updated entries with Cyclomatic Complexity (first 5):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 43\n",
      "   Cyclomatic Complexity: 10\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 19\n",
      "   Cyclomatic Complexity: 3\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   LOC: 13\n",
      "   Cyclomatic Complexity: 2\n",
      "   ---\n",
      "\n",
      "üîù Top 10 methods by Cyclomatic Complexity:\n",
      "1. main (Class: MavenWrapperDownloader)\n",
      "   CC: 10, LOC: 43\n",
      "2. equals (Class: OwnerDto)\n",
      "   CC: 10, LOC: 16\n",
      "3. equals (Class: PetDto)\n",
      "   CC: 9, LOC: 15\n",
      "4. equals (Class: ProblemDetailDto)\n",
      "   CC: 9, LOC: 15\n",
      "5. equals (Class: OwnerFieldsDto)\n",
      "   CC: 8, LOC: 14\n",
      "6. equals (Class: UserDto)\n",
      "   CC: 7, LOC: 13\n",
      "7. equals (Class: VetDto)\n",
      "   CC: 7, LOC: 13\n",
      "8. equals (Class: VisitDto)\n",
      "   CC: 7, LOC: 13\n",
      "9. saveUser (Class: UserServiceImpl)\n",
      "   CC: 6, LOC: 14\n",
      "10. addPetToOwner (Class: OwnersApi)\n",
      "   CC: 6, LOC: 27\n",
      "\n",
      "üíæ Updated dictionary with Cyclomatic Complexity saved to: enhanced_methods_with_complexity.json\n",
      "‚úÖ Enhanced dictionary now includes:\n",
      "  - method_name, parameters, return_type, class\n",
      "  - line_of_code\n",
      "  - cyclomatic_complexity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cyclomatic_complexity(function_body):\n",
    "    \"\"\"\n",
    "    Calculate Cyclomatic Complexity for a given function body.\n",
    "    \n",
    "    Simplified calculation: Count decision points + 1\n",
    "    Decision points include: if, else if, while, for, do-while, switch, case, \n",
    "    catch, ternary operators (?:), logical operators (&&, ||)\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return 1  # Base complexity for empty method\n",
    "    \n",
    "    function_body = str(function_body)\n",
    "    \n",
    "    # Initialize complexity (base complexity is 1)\n",
    "    complexity = 1\n",
    "    \n",
    "    # Keywords that add to cyclomatic complexity\n",
    "    decision_keywords = [\n",
    "        'if', 'else if', 'elseif', 'while', 'for', 'do', \n",
    "        'switch', 'case', 'catch', 'forEach'\n",
    "    ]\n",
    "    \n",
    "    # Convert to lowercase for case-insensitive matching\n",
    "    function_lower = function_body.lower()\n",
    "    \n",
    "    # Count decision keywords\n",
    "    for keyword in decision_keywords:\n",
    "        # Use word boundaries to avoid matching substrings\n",
    "        import re\n",
    "        pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "        matches = re.findall(pattern, function_lower)\n",
    "        complexity += len(matches)\n",
    "    \n",
    "    # Count logical operators (&&, ||) that create additional paths\n",
    "    logical_and_count = len(re.findall(r'&&', function_body))\n",
    "    logical_or_count = len(re.findall(r'\\|\\|', function_body))\n",
    "    complexity += logical_and_count + logical_or_count\n",
    "    \n",
    "    # Count ternary operators (?:)\n",
    "    ternary_count = len(re.findall(r'\\?[^?]*:', function_body))\n",
    "    complexity += ternary_count\n",
    "    \n",
    "    return max(1, complexity)  # Minimum complexity is 1\n",
    "\n",
    "# Calculate Cyclomatic Complexity for all methods and update the enhanced dictionary\n",
    "print(\"üîÑ Calculating Cyclomatic Complexity for all methods...\")\n",
    "\n",
    "# Check if enhanced_methods_dict_list exists\n",
    "if 'enhanced_methods_dict_list' not in globals():\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cell first.\")\n",
    "else:\n",
    "    # Create a copy to avoid modifying during iteration\n",
    "    updated_methods_list = []\n",
    "    \n",
    "    for i, method_entry in enumerate(enhanced_methods_dict_list):\n",
    "        # Get the original function body from ast_df for this method\n",
    "        method_name = method_entry['method_name']\n",
    "        class_name = method_entry['class']\n",
    "        \n",
    "        # Find the corresponding row in ast_df\n",
    "        matching_rows = ast_df[\n",
    "            (ast_df['Method Name'] == method_name) & \n",
    "            (ast_df['Class'] == class_name)\n",
    "        ]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            function_body = matching_rows.iloc[0]['Function Body']\n",
    "        else:\n",
    "            function_body = ''\n",
    "        \n",
    "        # Calculate cyclomatic complexity\n",
    "        cyclomatic_complexity = calculate_cyclomatic_complexity(function_body)\n",
    "        \n",
    "        # Create updated method entry with cyclomatic complexity\n",
    "        updated_method_entry = method_entry.copy()\n",
    "        updated_method_entry['cyclomatic_complexity'] = cyclomatic_complexity\n",
    "        \n",
    "        updated_methods_list.append(updated_method_entry)\n",
    "    \n",
    "    # Update the enhanced_methods_dict_list\n",
    "    enhanced_methods_dict_list = updated_methods_list\n",
    "    \n",
    "    print(f\"‚úÖ Updated {len(enhanced_methods_dict_list)} methods with Cyclomatic Complexity\")\n",
    "    \n",
    "    # Display statistics\n",
    "    complexity_values = [method['cyclomatic_complexity'] for method in enhanced_methods_dict_list]\n",
    "    \n",
    "    print(f\"\\nüìä Cyclomatic Complexity Statistics:\")\n",
    "    print(f\"Average CC: {np.mean(complexity_values):.2f}\")\n",
    "    print(f\"Median CC: {np.median(complexity_values):.2f}\")\n",
    "    print(f\"Min CC: {min(complexity_values)}\")\n",
    "    print(f\"Max CC: {max(complexity_values)}\")\n",
    "    print(f\"Standard Deviation: {np.std(complexity_values):.2f}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    complexity_counts = Counter(complexity_values)\n",
    "    print(f\"\\nüìà Complexity Distribution (top 10):\")\n",
    "    for cc, count in complexity_counts.most_common(10):\n",
    "        print(f\"  CC {cc}: {count} methods ({count/len(complexity_values)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample updated entries\n",
    "    print(f\"\\nüìã Sample updated entries with Cyclomatic Complexity (first 5):\")\n",
    "    for i, method in enumerate(enhanced_methods_dict_list[:5]):\n",
    "        print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "        print(f\"   Class: {method['class']}\")\n",
    "        print(f\"   LOC: {method['line_of_code']}\")\n",
    "        print(f\"   Cyclomatic Complexity: {method['cyclomatic_complexity']}\")\n",
    "        print(\"   ---\")\n",
    "    \n",
    "    # Show methods with highest cyclomatic complexity\n",
    "    sorted_by_complexity = sorted(enhanced_methods_dict_list, \n",
    "                                key=lambda x: x['cyclomatic_complexity'], \n",
    "                                reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 methods by Cyclomatic Complexity:\")\n",
    "    for i, method in enumerate(sorted_by_complexity[:10]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   CC: {method['cyclomatic_complexity']}, LOC: {method['line_of_code']}\")\n",
    "    \n",
    "    # Update the JSON file with cyclomatic complexity\n",
    "    updated_output_filename = \"enhanced_methods_with_complexity.json\"\n",
    "    with open(updated_output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Updated dictionary with Cyclomatic Complexity saved to: {updated_output_filename}\")\n",
    "    print(f\"‚úÖ Enhanced dictionary now includes:\")\n",
    "    print(f\"  - method_name, parameters, return_type, class\")\n",
    "    print(f\"  - line_of_code\")\n",
    "    print(f\"  - cyclomatic_complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4acf07",
   "metadata": {},
   "source": [
    "## 7. Add Cognitive Complexity to Method Dictionary\n",
    "\n",
    "Calculate Cognitive Complexity for each method and add it to the enhanced method dictionary. Cognitive Complexity is a measure of how difficult the code is to understand, focusing on the mental burden when reading code.\n",
    "\n",
    "**Key Differences from Cyclomatic Complexity:**\n",
    "- **Nesting increases complexity**: Nested control structures add more complexity\n",
    "- **Certain constructs are ignored**: `else`, `case`, `default` don't add complexity\n",
    "- **Binary logical operators**: Each use of `&&`, `||` in conditions adds +1\n",
    "- **Recursion**: Recursive calls add complexity\n",
    "\n",
    "**Cognitive Complexity Rules:**\n",
    "1. Base complexity = 0 (not 1 like Cyclomatic)\n",
    "2. Increment by 1 for: `if`, `while`, `for`, `do-while`, `switch`, `catch`, `goto`, `break`, `continue`\n",
    "3. Increment by nesting level for nested control structures\n",
    "4. Binary logical operators (`&&`, `||`) in conditions add +1 each\n",
    "5. Recursive calls add +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a82a4db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Calculating Cognitive Complexity for all methods...\n",
      "‚úÖ Updated 786 methods with Cognitive Complexity\n",
      "\n",
      "üìä Cognitive Complexity Statistics:\n",
      "Average Cognitive Complexity: 0.69\n",
      "Median Cognitive Complexity: 0.00\n",
      "Min Cognitive Complexity: 0\n",
      "Max Cognitive Complexity: 9\n",
      "Standard Deviation: 1.53\n",
      "\n",
      "üîÑ Comparison with Cyclomatic Complexity:\n",
      "Average CC: 1.59 vs Cognitive: 0.69\n",
      "Correlation between CC and Cognitive: 0.944\n",
      "\n",
      "üìà Cognitive Complexity Distribution (top 10):\n",
      "  Cognitive 0: 555 methods (70.6%)\n",
      "  Cognitive 1: 144 methods (18.3%)\n",
      "  Cognitive 6: 38 methods (4.8%)\n",
      "  Cognitive 3: 28 methods (3.6%)\n",
      "  Cognitive 2: 9 methods (1.1%)\n",
      "  Cognitive 4: 6 methods (0.8%)\n",
      "  Cognitive 8: 2 methods (0.3%)\n",
      "  Cognitive 5: 2 methods (0.3%)\n",
      "  Cognitive 9: 1 methods (0.1%)\n",
      "  Cognitive 7: 1 methods (0.1%)\n",
      "\n",
      "üìã Sample updated entries with both complexities (first 5):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 43\n",
      "   Cyclomatic Complexity: 10\n",
      "   Cognitive Complexity: 3\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 19\n",
      "   Cyclomatic Complexity: 3\n",
      "   Cognitive Complexity: 2\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   Cognitive Complexity: 0\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   LOC: 3\n",
      "   Cyclomatic Complexity: 1\n",
      "   Cognitive Complexity: 0\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   LOC: 13\n",
      "   Cyclomatic Complexity: 2\n",
      "   Cognitive Complexity: 1\n",
      "   ---\n",
      "\n",
      "üîù Top 10 methods by Cognitive Complexity:\n",
      "1. equals (Class: OwnerDto)\n",
      "   Cognitive: 9, Cyclomatic: 10, LOC: 16\n",
      "2. equals (Class: PetDto)\n",
      "   Cognitive: 8, Cyclomatic: 9, LOC: 15\n",
      "3. equals (Class: ProblemDetailDto)\n",
      "   Cognitive: 8, Cyclomatic: 9, LOC: 15\n",
      "4. equals (Class: OwnerFieldsDto)\n",
      "   Cognitive: 7, Cyclomatic: 8, LOC: 14\n",
      "5. failingRequest (Class: OopsApi)\n",
      "   Cognitive: 6, Cyclomatic: 3, LOC: 12\n",
      "6. addOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 5, LOC: 22\n",
      "7. addPetToOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "8. addVisitToOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "9. deleteOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "10. getOwner (Class: OwnersApi)\n",
      "   Cognitive: 6, Cyclomatic: 6, LOC: 27\n",
      "\n",
      "üéØ Top 5 methods with largest Cognitive vs Cyclomatic difference:\n",
      "1. main (Class: MavenWrapperDownloader)\n",
      "   Cognitive: 3, Cyclomatic: 10, Diff: 7\n",
      "2. findAll (Class: JdbcVetRepositoryImpl)\n",
      "   Cognitive: 1, Cyclomatic: 4, Diff: 3\n",
      "3. delete (Class: JpaPetTypeRepositoryImpl)\n",
      "   Cognitive: 1, Cyclomatic: 4, Diff: 3\n",
      "4. delete (Class: SpringDataPetTypeRepositoryImpl)\n",
      "   Cognitive: 1, Cyclomatic: 4, Diff: 3\n",
      "5. failingRequest (Class: OopsApi)\n",
      "   Cognitive: 6, Cyclomatic: 3, Diff: 3\n",
      "\n",
      "üíæ Updated dictionary with both complexity metrics saved to: enhanced_methods_with_all_complexity.json\n",
      "‚úÖ Enhanced dictionary now includes:\n",
      "  - method_name, parameters, return_type, class\n",
      "  - line_of_code\n",
      "  - cyclomatic_complexity\n",
      "  - cognitive_complexity\n"
     ]
    }
   ],
   "source": [
    "def calculate_cognitive_complexity(function_body, method_name=\"\"):\n",
    "    \"\"\"\n",
    "    Calculate Cognitive Complexity for a given function body.\n",
    "    \n",
    "    Cognitive Complexity focuses on how difficult code is to understand.\n",
    "    Unlike Cyclomatic Complexity, it considers nesting levels and ignores certain constructs.\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return 0  # Base cognitive complexity for empty method\n",
    "    \n",
    "    function_body = str(function_body)\n",
    "    complexity = 0\n",
    "    nesting_level = 0\n",
    "    \n",
    "    # Keywords that increment cognitive complexity\n",
    "    increment_keywords = [\n",
    "        'if', 'while', 'for', 'do', 'switch', 'catch', \n",
    "        'goto', 'break', 'continue', 'forEach'\n",
    "    ]\n",
    "    \n",
    "    # Keywords that increase nesting but don't add base complexity\n",
    "    nesting_keywords = ['if', 'while', 'for', 'do', 'switch', 'try', 'catch']\n",
    "    \n",
    "    # Split into lines for analysis\n",
    "    lines = function_body.split('\\n')\n",
    "    \n",
    "    for line in lines:\n",
    "        line_stripped = line.strip().lower()\n",
    "        line_original = line.strip()\n",
    "        \n",
    "        # Count opening braces to track nesting level changes\n",
    "        open_braces = line_original.count('{')\n",
    "        close_braces = line_original.count('}')\n",
    "        \n",
    "        # Check for control flow keywords that add complexity\n",
    "        for keyword in increment_keywords:\n",
    "            import re\n",
    "            pattern = r'\\b' + re.escape(keyword) + r'\\b'\n",
    "            if re.search(pattern, line_stripped):\n",
    "                # Add base complexity + nesting level\n",
    "                if keyword in nesting_keywords:\n",
    "                    complexity += 1 + nesting_level\n",
    "                    nesting_level += 1  # Increase nesting for next statements\n",
    "                else:\n",
    "                    complexity += 1 + nesting_level\n",
    "        \n",
    "        # Count binary logical operators in the line\n",
    "        logical_and_count = len(re.findall(r'&&', line_original))\n",
    "        logical_or_count = len(re.findall(r'\\|\\|', line_original))\n",
    "        complexity += logical_and_count + logical_or_count\n",
    "        \n",
    "        # Check for recursion (method calling itself)\n",
    "        if method_name and method_name in line_original:\n",
    "            # Simple check for method call (method_name followed by parentheses)\n",
    "            if re.search(rf'\\b{re.escape(method_name)}\\s*\\(', line_original):\n",
    "                complexity += 1\n",
    "        \n",
    "        # Update nesting level based on braces\n",
    "        # Note: This is a simplified approach\n",
    "        if open_braces > close_braces:\n",
    "            nesting_level += (open_braces - close_braces)\n",
    "        elif close_braces > open_braces:\n",
    "            nesting_level = max(0, nesting_level - (close_braces - open_braces))\n",
    "    \n",
    "    return complexity\n",
    "\n",
    "# Calculate Cognitive Complexity for all methods and update the enhanced dictionary\n",
    "print(\"üîÑ Calculating Cognitive Complexity for all methods...\")\n",
    "\n",
    "# Check if enhanced_methods_dict_list exists\n",
    "if 'enhanced_methods_dict_list' not in globals():\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    # Create a copy to avoid modifying during iteration\n",
    "    updated_methods_list = []\n",
    "    \n",
    "    for i, method_entry in enumerate(enhanced_methods_dict_list):\n",
    "        # Get the original function body from ast_df for this method\n",
    "        method_name = method_entry['method_name']\n",
    "        class_name = method_entry['class']\n",
    "        \n",
    "        # Find the corresponding row in ast_df\n",
    "        matching_rows = ast_df[\n",
    "            (ast_df['Method Name'] == method_name) & \n",
    "            (ast_df['Class'] == class_name)\n",
    "        ]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            function_body = matching_rows.iloc[0]['Function Body']\n",
    "        else:\n",
    "            function_body = ''\n",
    "        \n",
    "        # Calculate cognitive complexity\n",
    "        cognitive_complexity = calculate_cognitive_complexity(function_body, method_name)\n",
    "        \n",
    "        # Create updated method entry with cognitive complexity\n",
    "        updated_method_entry = method_entry.copy()\n",
    "        updated_method_entry['cognitive_complexity'] = cognitive_complexity\n",
    "        \n",
    "        updated_methods_list.append(updated_method_entry)\n",
    "    \n",
    "    # Update the enhanced_methods_dict_list\n",
    "    enhanced_methods_dict_list = updated_methods_list\n",
    "    \n",
    "    print(f\"‚úÖ Updated {len(enhanced_methods_dict_list)} methods with Cognitive Complexity\")\n",
    "    \n",
    "    # Display statistics\n",
    "    cognitive_values = [method['cognitive_complexity'] for method in enhanced_methods_dict_list]\n",
    "    cyclomatic_values = [method['cyclomatic_complexity'] for method in enhanced_methods_dict_list]\n",
    "    \n",
    "    print(f\"\\nüìä Cognitive Complexity Statistics:\")\n",
    "    print(f\"Average Cognitive Complexity: {np.mean(cognitive_values):.2f}\")\n",
    "    print(f\"Median Cognitive Complexity: {np.median(cognitive_values):.2f}\")\n",
    "    print(f\"Min Cognitive Complexity: {min(cognitive_values)}\")\n",
    "    print(f\"Max Cognitive Complexity: {max(cognitive_values)}\")\n",
    "    print(f\"Standard Deviation: {np.std(cognitive_values):.2f}\")\n",
    "    \n",
    "    # Compare with Cyclomatic Complexity\n",
    "    print(f\"\\nüîÑ Comparison with Cyclomatic Complexity:\")\n",
    "    print(f\"Average CC: {np.mean(cyclomatic_values):.2f} vs Cognitive: {np.mean(cognitive_values):.2f}\")\n",
    "    print(f\"Correlation between CC and Cognitive: {np.corrcoef(cyclomatic_values, cognitive_values)[0,1]:.3f}\")\n",
    "    \n",
    "    # Show distribution\n",
    "    cognitive_counts = Counter(cognitive_values)\n",
    "    print(f\"\\nüìà Cognitive Complexity Distribution (top 10):\")\n",
    "    for cc, count in cognitive_counts.most_common(10):\n",
    "        print(f\"  Cognitive {cc}: {count} methods ({count/len(cognitive_values)*100:.1f}%)\")\n",
    "    \n",
    "    # Show sample updated entries\n",
    "    print(f\"\\nüìã Sample updated entries with both complexities (first 5):\")\n",
    "    for i, method in enumerate(enhanced_methods_dict_list[:5]):\n",
    "        print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "        print(f\"   Class: {method['class']}\")\n",
    "        print(f\"   LOC: {method['line_of_code']}\")\n",
    "        print(f\"   Cyclomatic Complexity: {method['cyclomatic_complexity']}\")\n",
    "        print(f\"   Cognitive Complexity: {method['cognitive_complexity']}\")\n",
    "        print(\"   ---\")\n",
    "    \n",
    "    # Show methods with highest cognitive complexity\n",
    "    sorted_by_cognitive = sorted(enhanced_methods_dict_list, \n",
    "                               key=lambda x: x['cognitive_complexity'], \n",
    "                               reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 methods by Cognitive Complexity:\")\n",
    "    for i, method in enumerate(sorted_by_cognitive[:10]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   Cognitive: {method['cognitive_complexity']}, Cyclomatic: {method['cyclomatic_complexity']}, LOC: {method['line_of_code']}\")\n",
    "    \n",
    "    # Show methods where Cognitive and Cyclomatic differ significantly\n",
    "    complexity_diff = []\n",
    "    for method in enhanced_methods_dict_list:\n",
    "        diff = abs(method['cognitive_complexity'] - method['cyclomatic_complexity'])\n",
    "        complexity_diff.append((method, diff))\n",
    "    \n",
    "    complexity_diff.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(f\"\\nüéØ Top 5 methods with largest Cognitive vs Cyclomatic difference:\")\n",
    "    for i, (method, diff) in enumerate(complexity_diff[:5]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   Cognitive: {method['cognitive_complexity']}, Cyclomatic: {method['cyclomatic_complexity']}, Diff: {diff}\")\n",
    "    \n",
    "    # Update the JSON file with both complexity metrics\n",
    "    final_output_filename = \"enhanced_methods_with_all_complexity.json\"\n",
    "    with open(final_output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Updated dictionary with both complexity metrics saved to: {final_output_filename}\")\n",
    "    print(f\"‚úÖ Enhanced dictionary now includes:\")\n",
    "    print(f\"  - method_name, parameters, return_type, class\")\n",
    "    print(f\"  - line_of_code\")\n",
    "    print(f\"  - cyclomatic_complexity\")\n",
    "    print(f\"  - cognitive_complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ecabc7",
   "metadata": {},
   "source": [
    "## 8. Add Halstead Effort to Method Dictionary\n",
    "\n",
    "Calculate Halstead Effort for each method and add it to the enhanced method dictionary. Halstead Effort is a software complexity metric that measures the mental effort required to develop or understand a program.\n",
    "\n",
    "**Halstead Metrics:**\n",
    "- **n1**: Number of distinct operators\n",
    "- **n2**: Number of distinct operands  \n",
    "- **N1**: Total number of operators\n",
    "- **N2**: Total number of operands\n",
    "\n",
    "**Derived Metrics:**\n",
    "- **Program Length (N)**: N1 + N2\n",
    "- **Program Vocabulary (n)**: n1 + n2\n",
    "- **Program Volume (V)**: N √ó log‚ÇÇ(n)\n",
    "- **Program Difficulty (D)**: (n1/2) √ó (N2/n2)\n",
    "- **Program Effort (E)**: D √ó V\n",
    "\n",
    "**Java Operators include**: +, -, *, /, %, =, ==, !=, <, >, <=, >=, &&, ||, !, ++, --, +=, -=, etc., keywords like if, while, for, return, etc.\n",
    "\n",
    "**Java Operands include**: Variables, constants, method names, class names, literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cc38107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Calculating Halstead Effort for all methods...\n",
      "  Processing method 1/786\n",
      "  Processing method 101/786\n",
      "  Processing method 201/786\n",
      "  Processing method 301/786\n",
      "  Processing method 401/786\n",
      "  Processing method 501/786\n",
      "  Processing method 601/786\n",
      "  Processing method 701/786\n",
      "‚úÖ Updated 786 methods with Halstead Effort\n",
      "\n",
      "üìä Halstead Effort Statistics:\n",
      "Methods with non-zero effort: 682/786\n",
      "Average Halstead Effort: 4084.57\n",
      "Median Halstead Effort: 1386.97\n",
      "Min Halstead Effort: 1.00\n",
      "Max Halstead Effort: 68816.00\n",
      "Standard Deviation: 6790.14\n",
      "\n",
      "üìä Halstead Volume Statistics:\n",
      "Average Volume: 272.05\n",
      "Median Volume: 140.33\n",
      "Max Volume: 2671.38\n",
      "\n",
      "üìä Halstead Difficulty Statistics:\n",
      "Average Difficulty: 10.21\n",
      "Median Difficulty: 8.67\n",
      "Max Difficulty: 37.93\n",
      "\n",
      "üìã Sample updated entries with Halstead metrics (first 5):\n",
      "1. Method: 'main'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 43\n",
      "   Cyclomatic: 10\n",
      "   Cognitive: 3\n",
      "   Halstead Effort: 1699.17\n",
      "   Halstead Volume: 169.92\n",
      "   Halstead Difficulty: 10.00\n",
      "   ---\n",
      "2. Method: 'downloadFileFromURL'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 19\n",
      "   Cyclomatic: 3\n",
      "   Cognitive: 2\n",
      "   Halstead Effort: 16203.85\n",
      "   Halstead Volume: 866.52\n",
      "   Halstead Difficulty: 18.70\n",
      "   ---\n",
      "3. Method: 'getPasswordAuthentication'\n",
      "   Class: MavenWrapperDownloader\n",
      "   LOC: 3\n",
      "   Cyclomatic: 1\n",
      "   Cognitive: 0\n",
      "   Halstead Effort: 233.02\n",
      "   Halstead Volume: 46.60\n",
      "   Halstead Difficulty: 5.00\n",
      "   ---\n",
      "4. Method: 'main'\n",
      "   Class: PetClinicApplication\n",
      "   LOC: 3\n",
      "   Cyclomatic: 1\n",
      "   Cognitive: 0\n",
      "   Halstead Effort: 266.43\n",
      "   Halstead Volume: 55.51\n",
      "   Halstead Difficulty: 4.80\n",
      "   ---\n",
      "5. Method: 'customOpenAPI'\n",
      "   Class: SwaggerConfig\n",
      "   LOC: 13\n",
      "   Cyclomatic: 2\n",
      "   Cognitive: 1\n",
      "   Halstead Effort: 858.37\n",
      "   Halstead Volume: 163.50\n",
      "   Halstead Difficulty: 5.25\n",
      "   ---\n",
      "\n",
      "üîù Top 10 methods by Halstead Effort:\n",
      "1. listOwners (Class: OwnersApi)\n",
      "   Effort: 68816.00, Volume: 2041.43\n",
      "   Difficulty: 33.71, LOC: 17\n",
      "2. initOwners (Class: OwnerRestControllerTests)\n",
      "   Effort: 67027.43, Volume: 2671.38\n",
      "   Difficulty: 25.09, LOC: 41\n",
      "3. findById (Class: JdbcVetRepositoryImpl)\n",
      "   Effort: 35222.72, Volume: 1247.12\n",
      "   Difficulty: 28.24, LOC: 29\n",
      "4. listPets (Class: PetsApi)\n",
      "   Effort: 32886.29, Volume: 1298.14\n",
      "   Difficulty: 25.33, LOC: 17\n",
      "5. addOwner (Class: OwnersApi)\n",
      "   Effort: 32089.20, Volume: 1464.51\n",
      "   Difficulty: 21.91, LOC: 22\n",
      "6. deleteOwner (Class: OwnersApi)\n",
      "   Effort: 32089.20, Volume: 1464.51\n",
      "   Difficulty: 21.91, LOC: 27\n",
      "7. getOwner (Class: OwnersApi)\n",
      "   Effort: 32089.20, Volume: 1464.51\n",
      "   Difficulty: 21.91, LOC: 27\n",
      "8. updateOwner (Class: OwnersApi)\n",
      "   Effort: 32089.20, Volume: 1464.51\n",
      "   Difficulty: 21.91, LOC: 27\n",
      "9. shouldFindSpecialtiesByNameIn (Class: AbstractClinicServiceTests)\n",
      "   Effort: 31376.28, Volume: 1328.88\n",
      "   Difficulty: 23.61, LOC: 24\n",
      "10. mapRow (Class: JdbcVisitRowMapperExt)\n",
      "   Effort: 29064.06, Volume: 1472.08\n",
      "   Difficulty: 19.74, LOC: 30\n",
      "\n",
      "üîÑ Correlation Analysis with other metrics:\n",
      "Halstead Effort vs Cyclomatic Complexity: 0.616\n",
      "Halstead Effort vs Cognitive Complexity: 0.667\n",
      "Halstead Effort vs Lines of Code: 0.801\n",
      "\n",
      "üíæ Updated dictionary with all complexity metrics saved to: enhanced_methods_with_all_complexity.json\n",
      "‚úÖ Enhanced dictionary now includes:\n",
      "  - method_name, parameters, return_type, class, function_body\n",
      "  - line_of_code\n",
      "  - cyclomatic_complexity\n",
      "  - cognitive_complexity\n",
      "  - halstead_n1, halstead_n2, halstead_N1, halstead_N2\n",
      "  - halstead_length, halstead_vocabulary, halstead_volume\n",
      "  - halstead_difficulty, halstead_effort\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_halstead_effort(function_body):\n",
    "    \"\"\"\n",
    "    Calculate Halstead Effort for a given function body.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all Halstead metrics\n",
    "    \"\"\"\n",
    "    if pd.isna(function_body) or function_body == '' or function_body == 'null':\n",
    "        return {\n",
    "            'halstead_n1': 0, 'halstead_n2': 0, 'halstead_N1': 0, 'halstead_N2': 0,\n",
    "            'halstead_length': 0, 'halstead_vocabulary': 0, 'halstead_volume': 0,\n",
    "            'halstead_difficulty': 0, 'halstead_effort': 0\n",
    "        }\n",
    "    \n",
    "    function_body = str(function_body)\n",
    "    \n",
    "    # Define Java operators (including keywords that act as operators)\n",
    "    operators = [\n",
    "        # Arithmetic operators\n",
    "        '++', '--', '+=', '-=', '*=', '/=', '%=', '&=', '|=', '^=', '<<=', '>>=', '>>>=',\n",
    "        '+', '-', '*', '/', '%',\n",
    "        # Comparison operators\n",
    "        '==', '!=', '<=', '>=', '<', '>',\n",
    "        # Logical operators\n",
    "        '&&', '||', '!',\n",
    "        # Bitwise operators\n",
    "        '&', '|', '^', '~', '<<', '>>', '>>>',\n",
    "        # Assignment operator\n",
    "        '=',\n",
    "        # Other operators\n",
    "        '?', ':', '.', '->', '::', 'instanceof',\n",
    "        # Parentheses and brackets\n",
    "        '(', ')', '[', ']', '{', '}',\n",
    "        # Separators\n",
    "        ';', ',',\n",
    "        # Keywords that act as operators\n",
    "        'if', 'else', 'while', 'for', 'do', 'switch', 'case', 'default',\n",
    "        'try', 'catch', 'finally', 'throw', 'throws', 'return', 'break', 'continue',\n",
    "        'new', 'this', 'super', 'null', 'true', 'false',\n",
    "        'public', 'private', 'protected', 'static', 'final', 'abstract', 'synchronized',\n",
    "        'volatile', 'transient', 'native', 'strictfp',\n",
    "        'class', 'interface', 'enum', 'extends', 'implements', 'import', 'package'\n",
    "    ]\n",
    "    \n",
    "    # Sort operators by length (longest first) to avoid partial matches\n",
    "    operators.sort(key=len, reverse=True)\n",
    "    \n",
    "    # Remove comments and strings to avoid counting operators/operands inside them\n",
    "    # Simple approach: remove single-line comments and basic string literals\n",
    "    cleaned_code = re.sub(r'//.*$', '', function_body, flags=re.MULTILINE)\n",
    "    cleaned_code = re.sub(r'/\\*.*?\\*/', '', cleaned_code, flags=re.DOTALL)\n",
    "    cleaned_code = re.sub(r'\"[^\"]*\"', '\"\"', cleaned_code)  # Replace strings with empty strings\n",
    "    cleaned_code = re.sub(r\"'[^']*'\", \"''\", cleaned_code)  # Replace char literals\n",
    "    \n",
    "    # Count operators\n",
    "    operator_counts = Counter()\n",
    "    temp_code = cleaned_code\n",
    "    \n",
    "    for op in operators:\n",
    "        # Escape special regex characters\n",
    "        escaped_op = re.escape(op)\n",
    "        \n",
    "        # For keywords, use word boundaries\n",
    "        if op.isalpha():\n",
    "            pattern = r'\\b' + escaped_op + r'\\b'\n",
    "        else:\n",
    "            pattern = escaped_op\n",
    "            \n",
    "        matches = re.findall(pattern, temp_code)\n",
    "        if matches:\n",
    "            operator_counts[op] = len(matches)\n",
    "            # Remove found operators to avoid double counting\n",
    "            temp_code = re.sub(pattern, ' ', temp_code)\n",
    "    \n",
    "    # Count operands (identifiers, literals, etc.)\n",
    "    # Remove all operators first\n",
    "    operand_code = cleaned_code\n",
    "    for op in operators:\n",
    "        if op.isalpha():\n",
    "            pattern = r'\\b' + re.escape(op) + r'\\b'\n",
    "        else:\n",
    "            pattern = re.escape(op)\n",
    "        operand_code = re.sub(pattern, ' ', operand_code)\n",
    "    \n",
    "    # Extract operands (identifiers, numbers, remaining tokens)\n",
    "    operand_pattern = r'\\b[a-zA-Z_][a-zA-Z0-9_]*\\b|\\b\\d+\\.?\\d*\\b'\n",
    "    operands = re.findall(operand_pattern, operand_code)\n",
    "    \n",
    "    # Filter out empty strings and common noise\n",
    "    operands = [op for op in operands if op.strip() and not op.isspace()]\n",
    "    operand_counts = Counter(operands)\n",
    "    \n",
    "    # Calculate Halstead metrics\n",
    "    n1 = len(operator_counts)  # Number of distinct operators\n",
    "    n2 = len(operand_counts)   # Number of distinct operands\n",
    "    N1 = sum(operator_counts.values())  # Total number of operators\n",
    "    N2 = sum(operand_counts.values())   # Total number of operands\n",
    "    \n",
    "    # Derived metrics\n",
    "    N = N1 + N2  # Program length\n",
    "    n = n1 + n2  # Program vocabulary\n",
    "    \n",
    "    # Avoid division by zero and log of zero\n",
    "    if n > 0 and n2 > 0:\n",
    "        V = N * math.log2(n)  # Program volume\n",
    "        D = (n1 / 2) * (N2 / n2)  # Program difficulty\n",
    "        E = D * V  # Program effort\n",
    "    else:\n",
    "        V = D = E = 0\n",
    "    \n",
    "    return {\n",
    "        'halstead_n1': n1,\n",
    "        'halstead_n2': n2,\n",
    "        'halstead_N1': N1,\n",
    "        'halstead_N2': N2,\n",
    "        'halstead_length': N,\n",
    "        'halstead_vocabulary': n,\n",
    "        'halstead_volume': V,\n",
    "        'halstead_difficulty': D,\n",
    "        'halstead_effort': E\n",
    "    }\n",
    "\n",
    "# Calculate Halstead Effort for all methods and update the enhanced dictionary\n",
    "print(\"üîÑ Calculating Halstead Effort for all methods...\")\n",
    "\n",
    "# Check if enhanced_methods_dict_list exists\n",
    "if 'enhanced_methods_dict_list' not in globals():\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    # Create a copy to avoid modifying during iteration\n",
    "    updated_methods_list = []\n",
    "    \n",
    "    for i, method_entry in enumerate(enhanced_methods_dict_list):\n",
    "        if i % 100 == 0:  # Progress indicator\n",
    "            print(f\"  Processing method {i+1}/{len(enhanced_methods_dict_list)}\")\n",
    "        \n",
    "        # Get the original function body from ast_df for this method\n",
    "        method_name = method_entry['method_name']\n",
    "        class_name = method_entry['class']\n",
    "        \n",
    "        # Find the corresponding row in ast_df\n",
    "        matching_rows = ast_df[\n",
    "            (ast_df['Method Name'] == method_name) & \n",
    "            (ast_df['Class'] == class_name)\n",
    "        ]\n",
    "        \n",
    "        if len(matching_rows) > 0:\n",
    "            function_body = matching_rows.iloc[0]['Function Body']\n",
    "        else:\n",
    "            function_body = ''\n",
    "        \n",
    "        # Calculate Halstead metrics\n",
    "        halstead_metrics = calculate_halstead_effort(function_body)\n",
    "        \n",
    "        # Create updated method entry with Halstead metrics\n",
    "        updated_method_entry = method_entry.copy()\n",
    "        updated_method_entry.update(halstead_metrics)\n",
    "        \n",
    "        updated_methods_list.append(updated_method_entry)\n",
    "    \n",
    "    # Update the enhanced_methods_dict_list\n",
    "    enhanced_methods_dict_list = updated_methods_list\n",
    "    \n",
    "    print(f\"‚úÖ Updated {len(enhanced_methods_dict_list)} methods with Halstead Effort\")\n",
    "    \n",
    "    # Display statistics\n",
    "    effort_values = [method['halstead_effort'] for method in enhanced_methods_dict_list]\n",
    "    volume_values = [method['halstead_volume'] for method in enhanced_methods_dict_list]\n",
    "    difficulty_values = [method['halstead_difficulty'] for method in enhanced_methods_dict_list]\n",
    "    \n",
    "    # Filter out zero values for meaningful statistics\n",
    "    non_zero_effort = [e for e in effort_values if e > 0]\n",
    "    non_zero_volume = [v for v in volume_values if v > 0]\n",
    "    non_zero_difficulty = [d for d in difficulty_values if d > 0]\n",
    "    \n",
    "    print(f\"\\nüìä Halstead Effort Statistics:\")\n",
    "    print(f\"Methods with non-zero effort: {len(non_zero_effort)}/{len(effort_values)}\")\n",
    "    if non_zero_effort:\n",
    "        print(f\"Average Halstead Effort: {np.mean(non_zero_effort):.2f}\")\n",
    "        print(f\"Median Halstead Effort: {np.median(non_zero_effort):.2f}\")\n",
    "        print(f\"Min Halstead Effort: {min(non_zero_effort):.2f}\")\n",
    "        print(f\"Max Halstead Effort: {max(non_zero_effort):.2f}\")\n",
    "        print(f\"Standard Deviation: {np.std(non_zero_effort):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Halstead Volume Statistics:\")\n",
    "    if non_zero_volume:\n",
    "        print(f\"Average Volume: {np.mean(non_zero_volume):.2f}\")\n",
    "        print(f\"Median Volume: {np.median(non_zero_volume):.2f}\")\n",
    "        print(f\"Max Volume: {max(non_zero_volume):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüìä Halstead Difficulty Statistics:\")\n",
    "    if non_zero_difficulty:\n",
    "        print(f\"Average Difficulty: {np.mean(non_zero_difficulty):.2f}\")\n",
    "        print(f\"Median Difficulty: {np.median(non_zero_difficulty):.2f}\")\n",
    "        print(f\"Max Difficulty: {max(non_zero_difficulty):.2f}\")\n",
    "    \n",
    "    # Show sample updated entries\n",
    "    print(f\"\\nüìã Sample updated entries with Halstead metrics (first 5):\")\n",
    "    for i, method in enumerate(enhanced_methods_dict_list[:5]):\n",
    "        print(f\"{i+1}. Method: '{method['method_name']}'\")\n",
    "        print(f\"   Class: {method['class']}\")\n",
    "        print(f\"   LOC: {method['line_of_code']}\")\n",
    "        print(f\"   Cyclomatic: {method['cyclomatic_complexity']}\")\n",
    "        print(f\"   Cognitive: {method['cognitive_complexity']}\")\n",
    "        print(f\"   Halstead Effort: {method['halstead_effort']:.2f}\")\n",
    "        print(f\"   Halstead Volume: {method['halstead_volume']:.2f}\")\n",
    "        print(f\"   Halstead Difficulty: {method['halstead_difficulty']:.2f}\")\n",
    "        print(\"   ---\")\n",
    "    \n",
    "    # Show methods with highest Halstead effort\n",
    "    sorted_by_effort = sorted([m for m in enhanced_methods_dict_list if m['halstead_effort'] > 0], \n",
    "                            key=lambda x: x['halstead_effort'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 methods by Halstead Effort:\")\n",
    "    for i, method in enumerate(sorted_by_effort[:10]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   Effort: {method['halstead_effort']:.2f}, Volume: {method['halstead_volume']:.2f}\")\n",
    "        print(f\"   Difficulty: {method['halstead_difficulty']:.2f}, LOC: {method['line_of_code']}\")\n",
    "    \n",
    "    # Correlation analysis with other complexity metrics\n",
    "    if non_zero_effort:\n",
    "        # Get corresponding values for correlation\n",
    "        effort_for_corr = []\n",
    "        cyclomatic_for_corr = []\n",
    "        cognitive_for_corr = []\n",
    "        loc_for_corr = []\n",
    "        \n",
    "        for method in enhanced_methods_dict_list:\n",
    "            if method['halstead_effort'] > 0:\n",
    "                effort_for_corr.append(method['halstead_effort'])\n",
    "                cyclomatic_for_corr.append(method['cyclomatic_complexity'])\n",
    "                cognitive_for_corr.append(method['cognitive_complexity'])\n",
    "                loc_for_corr.append(method['line_of_code'])\n",
    "        \n",
    "        print(f\"\\nüîÑ Correlation Analysis with other metrics:\")\n",
    "        if len(effort_for_corr) > 1:\n",
    "            corr_cyclomatic = np.corrcoef(effort_for_corr, cyclomatic_for_corr)[0,1]\n",
    "            corr_cognitive = np.corrcoef(effort_for_corr, cognitive_for_corr)[0,1]\n",
    "            corr_loc = np.corrcoef(effort_for_corr, loc_for_corr)[0,1]\n",
    "            \n",
    "            print(f\"Halstead Effort vs Cyclomatic Complexity: {corr_cyclomatic:.3f}\")\n",
    "            print(f\"Halstead Effort vs Cognitive Complexity: {corr_cognitive:.3f}\")\n",
    "            print(f\"Halstead Effort vs Lines of Code: {corr_loc:.3f}\")\n",
    "    \n",
    "    # Update the JSON file with all complexity metrics including Halstead\n",
    "    final_output_filename = \"enhanced_methods_with_all_complexity.json\"\n",
    "    with open(final_output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(enhanced_methods_dict_list, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Updated dictionary with all complexity metrics saved to: {final_output_filename}\")\n",
    "    print(f\"‚úÖ Enhanced dictionary now includes:\")\n",
    "    print(f\"  - method_name, parameters, return_type, class, function_body\")\n",
    "    print(f\"  - line_of_code\")\n",
    "    print(f\"  - cyclomatic_complexity\")\n",
    "    print(f\"  - cognitive_complexity\")\n",
    "    print(f\"  - halstead_n1, halstead_n2, halstead_N1, halstead_N2\")\n",
    "    print(f\"  - halstead_length, halstead_vocabulary, halstead_volume\")\n",
    "    print(f\"  - halstead_difficulty, halstead_effort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae41e79",
   "metadata": {},
   "source": [
    "## 9. Calculate Normalized Static Weights and Update CSV\n",
    "\n",
    "Calculate normalized static importance weights for each method and add them as a new column to the CSV file. The process involves:\n",
    "\n",
    "1. **Percentile-based Normalization**: Convert raw metrics to normalized scores (0-1) where:\n",
    "   - Methods at ‚â•90th percentile get score = 1.0\n",
    "   - Methods at lower percentiles get proportionally lower scores\n",
    "   - Linear scaling between percentiles\n",
    "\n",
    "2. **Weighted Combination**: Combine four key complexity metrics with equal weights:\n",
    "   - **Lines of Code (25%)**: Method size indicator\n",
    "   - **Cyclomatic Complexity (25%)**: Control flow complexity  \n",
    "   - **Cognitive Complexity (25%)**: Mental effort to understand\n",
    "   - **Halstead Effort (25%)**: Programming effort required\n",
    "\n",
    "3. **Final Static Weight**: Sum of all weighted normalized scores (0-4 scale, then normalized to 0-1)\n",
    "\n",
    "The resulting \"Static Weight\" column will be added to `../methods.csv` for use in the hybrid RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bca18cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting static weight calculation process...\n",
      "üîÑ Calculating static weights...\n",
      "üìä Metric Statistics Before Normalization:\n",
      "LOC - Min: 0, Max: 43, Avg: 6.91\n",
      "Cyclomatic - Min: 1, Max: 10, Avg: 1.59\n",
      "Cognitive - Min: 0, Max: 9, Avg: 0.69\n",
      "Halstead Effort - Min: 0.10, Max: 68816.00, Avg: 3544.13\n",
      "\n",
      "üîÑ Normalizing metrics based on 90th percentile...\n",
      "\n",
      "üìä Normalization Statistics:\n",
      "LOC 90th percentile: 14.00\n",
      "Cyclomatic 90th percentile: 3.00\n",
      "Cognitive 90th percentile: 2.00\n",
      "Halstead 90th percentile: 10445.43\n",
      "\n",
      "üìä Static Weight Statistics:\n",
      "Average static weight: 0.2722\n",
      "Median static weight: 0.0807\n",
      "Min static weight: 0.0000\n",
      "Max static weight: 1.0000\n",
      "Standard deviation: 0.3002\n",
      "\n",
      "‚úÖ Static weights calculated for 786 methods\n",
      "\n",
      "üîù Top 10 methods by Static Weight:\n",
      "1. downloadFileFromURL (Class: MavenWrapperDownloader)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 19 (norm: 1.000)\n",
      "   Cyclomatic: 3 (norm: 1.000)\n",
      "   Cognitive: 2 (norm: 1.000)\n",
      "   Halstead: 16203.85 (norm: 1.000)\n",
      "   ---\n",
      "2. findById (Class: JdbcVetRepositoryImpl)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 29 (norm: 1.000)\n",
      "   Cyclomatic: 3 (norm: 1.000)\n",
      "   Cognitive: 3 (norm: 1.000)\n",
      "   Halstead: 35222.72 (norm: 1.000)\n",
      "   ---\n",
      "3. updateVet (Class: VetRestController)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 18 (norm: 1.000)\n",
      "   Cyclomatic: 4 (norm: 1.000)\n",
      "   Cognitive: 3 (norm: 1.000)\n",
      "   Halstead: 20743.87 (norm: 1.000)\n",
      "   ---\n",
      "4. saveUser (Class: UserServiceImpl)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 14 (norm: 1.000)\n",
      "   Cyclomatic: 6 (norm: 1.000)\n",
      "   Cognitive: 4 (norm: 1.000)\n",
      "   Halstead: 13307.49 (norm: 1.000)\n",
      "   ---\n",
      "5. shouldFindSpecialtiesByNameIn (Class: AbstractClinicServiceTests)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 24 (norm: 1.000)\n",
      "   Cyclomatic: 3 (norm: 1.000)\n",
      "   Cognitive: 2 (norm: 1.000)\n",
      "   Halstead: 31376.28 (norm: 1.000)\n",
      "   ---\n",
      "6. addOwner (Class: OwnersApi)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 22 (norm: 1.000)\n",
      "   Cyclomatic: 5 (norm: 1.000)\n",
      "   Cognitive: 6 (norm: 1.000)\n",
      "   Halstead: 32089.20 (norm: 1.000)\n",
      "   ---\n",
      "7. addPetToOwner (Class: OwnersApi)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 27 (norm: 1.000)\n",
      "   Cyclomatic: 6 (norm: 1.000)\n",
      "   Cognitive: 6 (norm: 1.000)\n",
      "   Halstead: 20612.76 (norm: 1.000)\n",
      "   ---\n",
      "8. addVisitToOwner (Class: OwnersApi)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 27 (norm: 1.000)\n",
      "   Cyclomatic: 6 (norm: 1.000)\n",
      "   Cognitive: 6 (norm: 1.000)\n",
      "   Halstead: 16160.14 (norm: 1.000)\n",
      "   ---\n",
      "9. deleteOwner (Class: OwnersApi)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 27 (norm: 1.000)\n",
      "   Cyclomatic: 6 (norm: 1.000)\n",
      "   Cognitive: 6 (norm: 1.000)\n",
      "   Halstead: 32089.20 (norm: 1.000)\n",
      "   ---\n",
      "10. getOwner (Class: OwnersApi)\n",
      "   Static Weight: 1.0000\n",
      "   LOC: 27 (norm: 1.000)\n",
      "   Cyclomatic: 6 (norm: 1.000)\n",
      "   Cognitive: 6 (norm: 1.000)\n",
      "   Halstead: 32089.20 (norm: 1.000)\n",
      "   ---\n",
      "\n",
      "üìà Static Weight Distribution:\n",
      "  Very Low (0.0-0.2): 454 methods (57.8%)\n",
      "  Low (0.2-0.4): 91 methods (11.6%)\n",
      "  Medium (0.4-0.6): 121 methods (15.4%)\n",
      "  High (0.6-0.8): 40 methods (5.1%)\n",
      "  Very High (0.8-1.0): 38 methods (4.8%)\n",
      "\n",
      "üíæ Methods with static weights saved to: enhanced_methods_with_static_weights.json\n",
      "‚úÖ Enhanced dictionary now includes static_weight and normalized metrics!\n",
      "üöÄ Starting CSV update process...\n",
      "üîÑ Updating CSV file: ../methods.csv\n",
      "‚úÖ Original CSV loaded: 786 rows\n",
      "üìä Created weight mapping for 785 methods\n",
      "‚úÖ Matched 479/786 methods\n",
      "üìä Static weights added to DataFrame\n",
      "üíæ Backup created: ../methods_backup.csv\n",
      "üíæ Updated CSV saved: ../methods.csv\n",
      "\n",
      "üìä CSV Update Statistics:\n",
      "Total methods in CSV: 786\n",
      "Methods with non-zero weights: 392\n",
      "Average static weight: 0.3766\n",
      "Max static weight: 1.0000\n",
      "\n",
      "üìã Sample of updated CSV data:\n",
      "                 Method Name                   Class  \\\n",
      "0                       main  MavenWrapperDownloader   \n",
      "1        downloadFileFromURL  MavenWrapperDownloader   \n",
      "2  getPasswordAuthentication  MavenWrapperDownloader   \n",
      "3                       main    PetClinicApplication   \n",
      "4              customOpenAPI           SwaggerConfig   \n",
      "5             swaggerContact           SwaggerConfig   \n",
      "6             swaggerLicense           SwaggerConfig   \n",
      "7                 toOwnerDto             OwnerMapper   \n",
      "8                    toOwner             OwnerMapper   \n",
      "9                    toOwner             OwnerMapper   \n",
      "\n",
      "                           Parameters             Return Type  Static Weight  \n",
      "0                         String args                    void       0.790666  \n",
      "1  String urlString, File destination                    void       1.000000  \n",
      "2                                 NaN  PasswordAuthentication       0.000000  \n",
      "3                       String[] args                    void       0.059946  \n",
      "4                                 NaN                 OpenAPI       0.000000  \n",
      "5                                 NaN                 Contact       0.000000  \n",
      "6                                 NaN                 License       0.000000  \n",
      "7                         Owner owner                OwnerDto       0.000000  \n",
      "8                   OwnerDto ownerDto                   Owner       0.000000  \n",
      "9             OwnerFieldsDto ownerDto                   Owner       0.000000  \n",
      "\n",
      "‚úÖ CSV file successfully updated with Static Weight column!\n",
      "\n",
      "üìä Static Weight Column Summary:\n",
      "Data type: float64\n",
      "Non-null values: 786\n",
      "Range: 0.0000 - 1.0000\n",
      "\n",
      "üìà Static Weight Distribution in CSV:\n",
      "  Very Low (0.0-0.2): 585 methods (74.4%)\n",
      "  Low (0.2-0.4): 18 methods (2.3%)\n",
      "  Medium (0.4-0.6): 77 methods (9.8%)\n",
      "  High (0.6-0.8): 33 methods (4.2%)\n",
      "  Very High (0.8-1.0): 73 methods (9.3%)\n",
      "\n",
      "üîù Top 5 methods by Static Weight in CSV:\n",
      "  downloadFileFromURL (Class: MavenWrapperDownloader) - Weight: 1.0000\n",
      "  findById (Class: JdbcVetRepositoryImpl) - Weight: 1.0000\n",
      "  updateVet (Class: VetRestController) - Weight: 1.0000\n",
      "  saveUser (Class: UserServiceImpl) - Weight: 1.0000\n",
      "  addOwner (Class: OwnersApi) - Weight: 1.0000\n",
      "\n",
      "üéØ The CSV file '../methods.csv' now contains a 'Static Weight' column!\n",
      "üìÅ Original file backed up with '_backup' suffix\n",
      "‚úÖ Ready for use in hybrid RAG system!\n"
     ]
    }
   ],
   "source": [
    "def normalize_by_percentile(values, max_value_percentile=90):\n",
    "    \"\"\"\n",
    "    Normalize values based on percentiles where 90th percentile = 1.0\n",
    "    \n",
    "    Args:\n",
    "        values: List of numeric values to normalize\n",
    "        max_value_percentile: Percentile that should map to 1.0 (default: 90)\n",
    "    \n",
    "    Returns:\n",
    "        List of normalized values between 0 and 1\n",
    "    \"\"\"\n",
    "    if not values or len(values) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Calculate the target percentile value\n",
    "    max_threshold = np.percentile(values, max_value_percentile)\n",
    "    min_val = np.min(values)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if max_threshold == min_val:\n",
    "        return [1.0] * len(values)\n",
    "    \n",
    "    # Normalize values\n",
    "    normalized = []\n",
    "    for val in values:\n",
    "        if val >= max_threshold:\n",
    "            normalized_val = 1.0\n",
    "        else:\n",
    "            # Linear scaling between min and max_threshold\n",
    "            normalized_val = (val - min_val) / (max_threshold - min_val)\n",
    "            normalized_val = max(0.0, min(1.0, normalized_val))  # Clamp to [0,1]\n",
    "        normalized.append(normalized_val)\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def calculate_static_weights(methods_dict_list):\n",
    "    \"\"\"\n",
    "    Calculate static importance weights for all methods\n",
    "    \n",
    "    Args:\n",
    "        methods_dict_list: List of method dictionaries with complexity metrics\n",
    "    \n",
    "    Returns:\n",
    "        List of method dictionaries with added 'static_weight' field\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Calculating static weights...\")\n",
    "    \n",
    "    # Extract the four key metrics for normalization\n",
    "    loc_values = [method['line_of_code'] for method in methods_dict_list]\n",
    "    cyclomatic_values = [method['cyclomatic_complexity'] for method in methods_dict_list]\n",
    "    cognitive_values = [method['cognitive_complexity'] for method in methods_dict_list]\n",
    "    halstead_effort_values = [method['halstead_effort'] for method in methods_dict_list]\n",
    "    \n",
    "    # Handle zero/missing values for Halstead effort\n",
    "    # Replace zero effort with a small positive value for better normalization\n",
    "    halstead_effort_cleaned = [max(val, 0.1) if val == 0 else val for val in halstead_effort_values]\n",
    "    \n",
    "    print(f\"üìä Metric Statistics Before Normalization:\")\n",
    "    print(f\"LOC - Min: {min(loc_values)}, Max: {max(loc_values)}, Avg: {np.mean(loc_values):.2f}\")\n",
    "    print(f\"Cyclomatic - Min: {min(cyclomatic_values)}, Max: {max(cyclomatic_values)}, Avg: {np.mean(cyclomatic_values):.2f}\")\n",
    "    print(f\"Cognitive - Min: {min(cognitive_values)}, Max: {max(cognitive_values)}, Avg: {np.mean(cognitive_values):.2f}\")\n",
    "    print(f\"Halstead Effort - Min: {min(halstead_effort_cleaned):.2f}, Max: {max(halstead_effort_cleaned):.2f}, Avg: {np.mean(halstead_effort_cleaned):.2f}\")\n",
    "    \n",
    "    # Normalize each metric based on 90th percentile\n",
    "    print(\"\\nüîÑ Normalizing metrics based on 90th percentile...\")\n",
    "    \n",
    "    normalized_loc = normalize_by_percentile(loc_values)\n",
    "    normalized_cyclomatic = normalize_by_percentile(cyclomatic_values)\n",
    "    normalized_cognitive = normalize_by_percentile(cognitive_values)\n",
    "    normalized_halstead = normalize_by_percentile(halstead_effort_cleaned)\n",
    "    \n",
    "    # Display normalization statistics\n",
    "    print(f\"\\nüìä Normalization Statistics:\")\n",
    "    print(f\"LOC 90th percentile: {np.percentile(loc_values, 90):.2f}\")\n",
    "    print(f\"Cyclomatic 90th percentile: {np.percentile(cyclomatic_values, 90):.2f}\")\n",
    "    print(f\"Cognitive 90th percentile: {np.percentile(cognitive_values, 90):.2f}\")\n",
    "    print(f\"Halstead 90th percentile: {np.percentile(halstead_effort_cleaned, 90):.2f}\")\n",
    "    \n",
    "    # Calculate weighted static importance (25% each)\n",
    "    weight_per_metric = 0.25\n",
    "    static_weights = []\n",
    "    \n",
    "    for i in range(len(methods_dict_list)):\n",
    "        static_weight = (\n",
    "            normalized_loc[i] * weight_per_metric +\n",
    "            normalized_cyclomatic[i] * weight_per_metric +\n",
    "            normalized_cognitive[i] * weight_per_metric +\n",
    "            normalized_halstead[i] * weight_per_metric\n",
    "        )\n",
    "        static_weights.append(static_weight)\n",
    "    \n",
    "    # Add static weights to method dictionaries\n",
    "    updated_methods = []\n",
    "    for i, method in enumerate(methods_dict_list):\n",
    "        updated_method = method.copy()\n",
    "        updated_method['static_weight'] = static_weights[i]\n",
    "        updated_method['normalized_loc'] = normalized_loc[i]\n",
    "        updated_method['normalized_cyclomatic'] = normalized_cyclomatic[i]\n",
    "        updated_method['normalized_cognitive'] = normalized_cognitive[i]\n",
    "        updated_method['normalized_halstead_effort'] = normalized_halstead[i]\n",
    "        updated_methods.append(updated_method)\n",
    "    \n",
    "    print(f\"\\nüìä Static Weight Statistics:\")\n",
    "    print(f\"Average static weight: {np.mean(static_weights):.4f}\")\n",
    "    print(f\"Median static weight: {np.median(static_weights):.4f}\")\n",
    "    print(f\"Min static weight: {min(static_weights):.4f}\")\n",
    "    print(f\"Max static weight: {max(static_weights):.4f}\")\n",
    "    print(f\"Standard deviation: {np.std(static_weights):.4f}\")\n",
    "    \n",
    "    return updated_methods\n",
    "\n",
    "# Calculate static weights for all methods\n",
    "print(\"üöÄ Starting static weight calculation process...\")\n",
    "\n",
    "if 'enhanced_methods_dict_list' not in globals():\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cells first.\")\n",
    "else:\n",
    "    # Calculate static weights\n",
    "    methods_with_weights = calculate_static_weights(enhanced_methods_dict_list)\n",
    "    \n",
    "    # Update the global variable\n",
    "    enhanced_methods_dict_list = methods_with_weights\n",
    "    \n",
    "    print(f\"\\n‚úÖ Static weights calculated for {len(methods_with_weights)} methods\")\n",
    "    \n",
    "    # Show top 10 methods by static weight\n",
    "    sorted_by_weight = sorted(methods_with_weights, \n",
    "                            key=lambda x: x['static_weight'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    print(f\"\\nüîù Top 10 methods by Static Weight:\")\n",
    "    for i, method in enumerate(sorted_by_weight[:10]):\n",
    "        print(f\"{i+1}. {method['method_name']} (Class: {method['class']})\")\n",
    "        print(f\"   Static Weight: {method['static_weight']:.4f}\")\n",
    "        print(f\"   LOC: {method['line_of_code']} (norm: {method['normalized_loc']:.3f})\")\n",
    "        print(f\"   Cyclomatic: {method['cyclomatic_complexity']} (norm: {method['normalized_cyclomatic']:.3f})\")\n",
    "        print(f\"   Cognitive: {method['cognitive_complexity']} (norm: {method['normalized_cognitive']:.3f})\")\n",
    "        print(f\"   Halstead: {method['halstead_effort']:.2f} (norm: {method['normalized_halstead_effort']:.3f})\")\n",
    "        print(\"   ---\")\n",
    "    \n",
    "    # Show distribution of static weights\n",
    "    weight_values = [method['static_weight'] for method in methods_with_weights]\n",
    "    weight_ranges = [\n",
    "        (0.0, 0.2, \"Very Low\"),\n",
    "        (0.2, 0.4, \"Low\"), \n",
    "        (0.4, 0.6, \"Medium\"),\n",
    "        (0.6, 0.8, \"High\"),\n",
    "        (0.8, 1.0, \"Very High\")\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìà Static Weight Distribution:\")\n",
    "    for min_w, max_w, label in weight_ranges:\n",
    "        count = sum(1 for w in weight_values if min_w <= w < max_w)\n",
    "        percentage = (count / len(weight_values)) * 100\n",
    "        print(f\"  {label} ({min_w:.1f}-{max_w:.1f}): {count} methods ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Save updated data with static weights\n",
    "    weights_output_filename = \"enhanced_methods_with_static_weights.json\"\n",
    "    with open(weights_output_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(methods_with_weights, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Methods with static weights saved to: {weights_output_filename}\")\n",
    "    print(f\"‚úÖ Enhanced dictionary now includes static_weight and normalized metrics!\")\n",
    "\n",
    "# Update the original CSV file with static weights\n",
    "def update_csv_with_static_weights(csv_file_path, methods_with_weights):\n",
    "    \"\"\"\n",
    "    Update the original CSV file by adding a 'Static Weight' column\n",
    "    \n",
    "    Args:\n",
    "        csv_file_path: Path to the original CSV file\n",
    "        methods_with_weights: List of method dictionaries with static weights\n",
    "    \"\"\"\n",
    "    print(f\"üîÑ Updating CSV file: {csv_file_path}\")\n",
    "    \n",
    "    try:\n",
    "        # Read the original CSV\n",
    "        original_df = pd.read_csv(csv_file_path)\n",
    "        print(f\"‚úÖ Original CSV loaded: {len(original_df)} rows\")\n",
    "        \n",
    "        # Create a mapping from method signature to static weight\n",
    "        weight_mapping = {}\n",
    "        for method in methods_with_weights:\n",
    "            # Create a unique identifier for each method\n",
    "            method_key = (\n",
    "                method['method_name'],\n",
    "                method['class'],\n",
    "                str(method['parameters']),\n",
    "                str(method['return_type'])\n",
    "            )\n",
    "            weight_mapping[method_key] = method['static_weight']\n",
    "        \n",
    "        print(f\"üìä Created weight mapping for {len(weight_mapping)} methods\")\n",
    "        \n",
    "        # Add static weight column to the original DataFrame\n",
    "        static_weights = []\n",
    "        matches_found = 0\n",
    "        \n",
    "        for _, row in original_df.iterrows():\n",
    "            # Create the same key format for matching\n",
    "            row_key = (\n",
    "                str(row.get('Method Name', row.get('Method', ''))),\n",
    "                str(row.get('Class', row.get('ClassName', ''))),\n",
    "                str(row.get('Parameters', row.get('Parameter', ''))),\n",
    "                str(row.get('Return Type', row.get('ReturnType', '')))\n",
    "            )\n",
    "            \n",
    "            # Look up the static weight\n",
    "            if row_key in weight_mapping:\n",
    "                static_weights.append(weight_mapping[row_key])\n",
    "                matches_found += 1\n",
    "            else:\n",
    "                # Default weight for unmatched methods\n",
    "                static_weights.append(0.0)\n",
    "        \n",
    "        # Add the Static Weight column\n",
    "        original_df['Static Weight'] = static_weights\n",
    "        \n",
    "        print(f\"‚úÖ Matched {matches_found}/{len(original_df)} methods\")\n",
    "        print(f\"üìä Static weights added to DataFrame\")\n",
    "        \n",
    "        # Save the updated CSV\n",
    "        backup_file = csv_file_path.replace('.csv', '_backup.csv')\n",
    "        original_df_backup = pd.read_csv(csv_file_path)\n",
    "        original_df_backup.to_csv(backup_file, index=False)\n",
    "        print(f\"üíæ Backup created: {backup_file}\")\n",
    "        \n",
    "        # Save the updated CSV\n",
    "        original_df.to_csv(csv_file_path, index=False)\n",
    "        print(f\"üíæ Updated CSV saved: {csv_file_path}\")\n",
    "        \n",
    "        # Display statistics\n",
    "        non_zero_weights = [w for w in static_weights if w > 0]\n",
    "        print(f\"\\nüìä CSV Update Statistics:\")\n",
    "        print(f\"Total methods in CSV: {len(static_weights)}\")\n",
    "        print(f\"Methods with non-zero weights: {len(non_zero_weights)}\")\n",
    "        print(f\"Average static weight: {np.mean(non_zero_weights):.4f}\")\n",
    "        print(f\"Max static weight: {max(static_weights):.4f}\")\n",
    "        \n",
    "        # Show sample of updated data\n",
    "        print(f\"\\nüìã Sample of updated CSV data:\")\n",
    "        sample_cols = ['Method Name', 'Class', 'Parameters', 'Return Type', 'Static Weight']\n",
    "        available_cols = [col for col in sample_cols if col in original_df.columns]\n",
    "        if available_cols:\n",
    "            print(original_df[available_cols].head(10))\n",
    "        \n",
    "        return original_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating CSV: {e}\")\n",
    "        return None\n",
    "\n",
    "# Update the CSV file with static weights\n",
    "csv_file_path = \"../methods.csv\"\n",
    "\n",
    "if 'enhanced_methods_dict_list' in globals():\n",
    "    print(\"üöÄ Starting CSV update process...\")\n",
    "    \n",
    "    # Update the CSV file\n",
    "    updated_df = update_csv_with_static_weights(csv_file_path, enhanced_methods_dict_list)\n",
    "    \n",
    "    if updated_df is not None:\n",
    "        print(\"\\n‚úÖ CSV file successfully updated with Static Weight column!\")\n",
    "        \n",
    "        # Show the new column info\n",
    "        if 'Static Weight' in updated_df.columns:\n",
    "            print(f\"\\nüìä Static Weight Column Summary:\")\n",
    "            print(f\"Data type: {updated_df['Static Weight'].dtype}\")\n",
    "            print(f\"Non-null values: {updated_df['Static Weight'].notna().sum()}\")\n",
    "            print(f\"Range: {updated_df['Static Weight'].min():.4f} - {updated_df['Static Weight'].max():.4f}\")\n",
    "            \n",
    "            # Show distribution\n",
    "            print(f\"\\nüìà Static Weight Distribution in CSV:\")\n",
    "            weight_bins = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "            weight_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "            \n",
    "            for i in range(len(weight_bins)-1):\n",
    "                min_w, max_w = weight_bins[i], weight_bins[i+1]\n",
    "                count = ((updated_df['Static Weight'] >= min_w) & (updated_df['Static Weight'] < max_w)).sum()\n",
    "                if i == len(weight_bins)-2:  # Last bin includes max value\n",
    "                    count = ((updated_df['Static Weight'] >= min_w) & (updated_df['Static Weight'] <= max_w)).sum()\n",
    "                percentage = (count / len(updated_df)) * 100\n",
    "                print(f\"  {weight_labels[i]} ({min_w:.1f}-{max_w:.1f}): {count} methods ({percentage:.1f}%)\")\n",
    "            \n",
    "            # Show top methods by static weight in CSV\n",
    "            top_methods = updated_df.nlargest(5, 'Static Weight')\n",
    "            print(f\"\\nüîù Top 5 methods by Static Weight in CSV:\")\n",
    "            for idx, row in top_methods.iterrows():\n",
    "                method_name = row.get('Method Name', row.get('Method', 'Unknown'))\n",
    "                class_name = row.get('Class', row.get('ClassName', 'Unknown'))\n",
    "                static_weight = row['Static Weight']\n",
    "                print(f\"  {method_name} (Class: {class_name}) - Weight: {static_weight:.4f}\")\n",
    "        \n",
    "        print(f\"\\nüéØ The CSV file '{csv_file_path}' now contains a 'Static Weight' column!\")\n",
    "        print(f\"üìÅ Original file backed up with '_backup' suffix\")\n",
    "        print(f\"‚úÖ Ready for use in hybrid RAG system!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Failed to update CSV file\")\n",
    "else:\n",
    "    print(\"‚ùå enhanced_methods_dict_list not found. Please run the previous cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e503d235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
